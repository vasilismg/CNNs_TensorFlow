{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect hapiness \n",
    "\n",
    "This notebook is based on the programming assignment of deeplearning.ai, course Convolutional Neural Networks, week Deep convolutional models case studies\n",
    "\n",
    "We will build an algorithm that recognizes whether the person in a picture is happy or not.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Application of Convolutional Neural Networks in TensorFlow\n",
    "- Apply Batch Normalization\n",
    "- Use of Adam optimizer \n",
    "- Use of GPU for the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import SVG\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import time\n",
    "import math\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_happy.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_happy.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "    \n",
    "    inputs_ = tf.placeholder(tf.float32,[None,64,64,3],name='inputs_')\n",
    "    targets_ = tf.placeholder(tf.float32,[None,1], name='targets_')\n",
    "    training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "    \n",
    "    return inputs_, targets_, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss(logits, targets):\n",
    "        \n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=targets))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate):\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HappyModel:\n",
    "    \n",
    "    def __init__(self, learning_rate):\n",
    "    \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs_, self.targets_, self.training = build_inputs()\n",
    "        \n",
    "        # Zero-Padding\n",
    "        paddings = tf.constant([[0, 0], [3, 3,], [3, 3], [0, 0]])\n",
    "        self.X = tf.pad(self.inputs_, paddings, \"CONSTANT\")\n",
    "        \n",
    "        # CONV -> BN -> RELU Block applied to X\n",
    "        strides = 1        \n",
    "        self.X = tf.layers.conv2d(self.X, 32, kernel_size = [7, 7], strides = [strides, strides],\n",
    "                             padding='VALID',name = 'conv0')\n",
    "        self.X = tf.layers.batch_normalization(self.X, training=self.training, name = 'bn0')\n",
    "        self.X = tf.nn.relu(self.X)\n",
    "        \n",
    "        # MAXPOOL\n",
    "        self.X = tf.nn.max_pool(self.X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "        \n",
    "        # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "        self.X = tf.contrib.layers.flatten(self.X)\n",
    "        self.X = tf.contrib.layers.fully_connected(self.X, 1, activation_fn=None)\n",
    "        self.prediction = tf.nn.sigmoid(self.X) \n",
    "        \n",
    "        self.loss = build_loss(self.X, self.targets_)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate)\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.round(self.prediction), self.targets_)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        self.acc, self.acc_op = tf.metrics.accuracy(labels=self.targets_, \n",
    "                                  predictions=tf.round(self.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "mini_batch_size = 16\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "\n",
    "Y_train = tf.transpose(Y_train_orig)\n",
    "Y_test = tf.transpose(Y_test_orig)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    Y_train,Y_test = sess.run([Y_train,Y_test])\n",
    "    \n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0812 22:38:31.030511 30984 deprecation.py:323] From <ipython-input-9-5c64e489e3d6>:17: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0812 22:38:31.033517 30984 deprecation.py:506] From C:\\Users\\vgkortsas\\AppData\\Local\\Continuum\\anaconda3\\envs\\TF_practice\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0812 22:38:31.189118 30984 deprecation.py:323] From <ipython-input-9-5c64e489e3d6>:18: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0812 22:38:32.320299 30984 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0812 22:38:32.321289 30984 deprecation.py:323] From C:\\Users\\vgkortsas\\AppData\\Local\\Continuum\\anaconda3\\envs\\TF_practice\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0812 22:38:32.679507 30984 deprecation.py:323] From C:\\Users\\vgkortsas\\AppData\\Local\\Continuum\\anaconda3\\envs\\TF_practice\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/80 Iteration: 5 Train loss: 0.829 Train accuracy: 0.4750\n",
      "Epoch: 1/80 Iteration: 10 Train loss: 0.575 Train accuracy: 0.6313\n",
      "Epoch: 1/80 Iteration: 15 Train loss: 0.280 Train accuracy: 0.6917\n",
      "Epoch: 1/80 Iteration: 20 Train loss: 0.306 Train accuracy: 0.7219\n",
      "Epoch: 1/80 Iteration: 25 Train loss: 0.758 Train accuracy: 0.7250\n",
      "Epoch: 1/80 Iteration: 30 Train loss: 0.070 Train accuracy: 0.7437\n",
      "Epoch: 1/80 Iteration: 35 Train loss: 0.311 Train accuracy: 0.7536\n",
      "Train accuracy (mean): 0.6675\n",
      "Epoch: 2/80 Iteration: 5 Train loss: 0.169 Train accuracy: 0.7676\n",
      "Epoch: 2/80 Iteration: 10 Train loss: 0.106 Train accuracy: 0.7750\n",
      "Epoch: 2/80 Iteration: 15 Train loss: 0.163 Train accuracy: 0.7881\n",
      "Epoch: 2/80 Iteration: 20 Train loss: 0.343 Train accuracy: 0.7935\n",
      "Epoch: 2/80 Iteration: 25 Train loss: 0.133 Train accuracy: 0.8040\n",
      "Epoch: 2/80 Iteration: 30 Train loss: 0.085 Train accuracy: 0.8148\n",
      "Epoch: 2/80 Iteration: 35 Train loss: 0.139 Train accuracy: 0.8233\n",
      "Train accuracy (mean): 0.7937\n",
      "Epoch: 3/80 Iteration: 5 Train loss: 0.246 Train accuracy: 0.8273\n",
      "Epoch: 3/80 Iteration: 10 Train loss: 0.199 Train accuracy: 0.8301\n",
      "Epoch: 3/80 Iteration: 15 Train loss: 0.085 Train accuracy: 0.8354\n",
      "Epoch: 3/80 Iteration: 20 Train loss: 0.253 Train accuracy: 0.8382\n",
      "Epoch: 3/80 Iteration: 25 Train loss: 0.050 Train accuracy: 0.8431\n",
      "Epoch: 3/80 Iteration: 30 Train loss: 0.030 Train accuracy: 0.8482\n",
      "Epoch: 3/80 Iteration: 35 Train loss: 0.074 Train accuracy: 0.8523\n",
      "Train accuracy (mean): 0.8389\n",
      "Epoch: 4/80 Iteration: 5 Train loss: 0.103 Train accuracy: 0.8569\n",
      "Epoch: 4/80 Iteration: 10 Train loss: 0.070 Train accuracy: 0.8582\n",
      "Epoch: 4/80 Iteration: 15 Train loss: 0.042 Train accuracy: 0.8613\n",
      "Epoch: 4/80 Iteration: 20 Train loss: 0.220 Train accuracy: 0.8642\n",
      "Epoch: 4/80 Iteration: 25 Train loss: 0.059 Train accuracy: 0.8677\n",
      "Epoch: 4/80 Iteration: 30 Train loss: 0.158 Train accuracy: 0.8715\n",
      "Epoch: 4/80 Iteration: 35 Train loss: 0.297 Train accuracy: 0.8733\n",
      "Train accuracy (mean): 0.8643\n",
      "Epoch: 5/80 Iteration: 5 Train loss: 0.291 Train accuracy: 0.8722\n",
      "Epoch: 5/80 Iteration: 10 Train loss: 0.205 Train accuracy: 0.8719\n",
      "Epoch: 5/80 Iteration: 15 Train loss: 0.035 Train accuracy: 0.8739\n",
      "Epoch: 5/80 Iteration: 20 Train loss: 0.197 Train accuracy: 0.8750\n",
      "Epoch: 5/80 Iteration: 25 Train loss: 0.039 Train accuracy: 0.8775\n",
      "Epoch: 5/80 Iteration: 30 Train loss: 0.043 Train accuracy: 0.8795\n",
      "Epoch: 5/80 Iteration: 35 Train loss: 0.106 Train accuracy: 0.8818\n",
      "Train accuracy (mean): 0.8759\n",
      "Epoch: 6/80 Iteration: 5 Train loss: 0.039 Train accuracy: 0.8828\n",
      "Epoch: 6/80 Iteration: 10 Train loss: 0.087 Train accuracy: 0.8823\n",
      "Epoch: 6/80 Iteration: 15 Train loss: 0.040 Train accuracy: 0.8827\n",
      "Epoch: 6/80 Iteration: 20 Train loss: 0.317 Train accuracy: 0.8831\n",
      "Epoch: 6/80 Iteration: 25 Train loss: 0.038 Train accuracy: 0.8853\n",
      "Epoch: 6/80 Iteration: 30 Train loss: 0.165 Train accuracy: 0.8874\n",
      "Epoch: 6/80 Iteration: 35 Train loss: 0.186 Train accuracy: 0.8890\n",
      "Train accuracy (mean): 0.8844\n",
      "Epoch: 7/80 Iteration: 5 Train loss: 0.049 Train accuracy: 0.8889\n",
      "Epoch: 7/80 Iteration: 10 Train loss: 0.055 Train accuracy: 0.8880\n",
      "Epoch: 7/80 Iteration: 15 Train loss: 0.012 Train accuracy: 0.8885\n",
      "Epoch: 7/80 Iteration: 20 Train loss: 0.257 Train accuracy: 0.8888\n",
      "Epoch: 7/80 Iteration: 25 Train loss: 0.017 Train accuracy: 0.8898\n",
      "Epoch: 7/80 Iteration: 30 Train loss: 0.003 Train accuracy: 0.8914\n",
      "Epoch: 7/80 Iteration: 35 Train loss: 0.016 Train accuracy: 0.8928\n",
      "Train accuracy (mean): 0.8896\n",
      "Epoch: 8/80 Iteration: 5 Train loss: 0.029 Train accuracy: 0.8935\n",
      "Epoch: 8/80 Iteration: 10 Train loss: 0.008 Train accuracy: 0.8940\n",
      "Epoch: 8/80 Iteration: 15 Train loss: 0.460 Train accuracy: 0.8948\n",
      "Epoch: 8/80 Iteration: 20 Train loss: 0.333 Train accuracy: 0.8965\n",
      "Epoch: 8/80 Iteration: 25 Train loss: 0.133 Train accuracy: 0.8976\n",
      "Epoch: 8/80 Iteration: 30 Train loss: 0.048 Train accuracy: 0.8985\n",
      "Epoch: 8/80 Iteration: 35 Train loss: 0.042 Train accuracy: 0.9000\n",
      "Train accuracy (mean): 0.8964\n",
      "Epoch: 9/80 Iteration: 5 Train loss: 0.030 Train accuracy: 0.9000\n",
      "Epoch: 9/80 Iteration: 10 Train loss: 0.017 Train accuracy: 0.9004\n",
      "Epoch: 9/80 Iteration: 15 Train loss: 0.486 Train accuracy: 0.9012\n",
      "Epoch: 9/80 Iteration: 20 Train loss: 0.341 Train accuracy: 0.9023\n",
      "Epoch: 9/80 Iteration: 25 Train loss: 0.061 Train accuracy: 0.9037\n",
      "Epoch: 9/80 Iteration: 30 Train loss: 0.032 Train accuracy: 0.9045\n",
      "Epoch: 9/80 Iteration: 35 Train loss: 0.059 Train accuracy: 0.9056\n",
      "Train accuracy (mean): 0.9025\n",
      "Epoch: 10/80 Iteration: 5 Train loss: 0.412 Train accuracy: 0.9058\n",
      "Epoch: 10/80 Iteration: 10 Train loss: 0.379 Train accuracy: 0.9059\n",
      "Epoch: 10/80 Iteration: 15 Train loss: 0.310 Train accuracy: 0.9062\n",
      "Epoch: 10/80 Iteration: 20 Train loss: 0.200 Train accuracy: 0.9070\n",
      "Epoch: 10/80 Iteration: 25 Train loss: 0.007 Train accuracy: 0.9078\n",
      "Epoch: 10/80 Iteration: 30 Train loss: 0.192 Train accuracy: 0.9087\n",
      "Epoch: 10/80 Iteration: 35 Train loss: 0.023 Train accuracy: 0.9096\n",
      "Train accuracy (mean): 0.9073\n",
      "Epoch: 11/80 Iteration: 5 Train loss: 0.138 Train accuracy: 0.9095\n",
      "Epoch: 11/80 Iteration: 10 Train loss: 0.291 Train accuracy: 0.9101\n",
      "Epoch: 11/80 Iteration: 15 Train loss: 0.002 Train accuracy: 0.9107\n",
      "Epoch: 11/80 Iteration: 20 Train loss: 0.397 Train accuracy: 0.9104\n",
      "Epoch: 11/80 Iteration: 25 Train loss: 0.099 Train accuracy: 0.9102\n",
      "Epoch: 11/80 Iteration: 30 Train loss: 0.411 Train accuracy: 0.9105\n",
      "Epoch: 11/80 Iteration: 35 Train loss: 0.019 Train accuracy: 0.9110\n",
      "Train accuracy (mean): 0.9103\n",
      "Epoch: 12/80 Iteration: 5 Train loss: 0.755 Train accuracy: 0.9108\n",
      "Epoch: 12/80 Iteration: 10 Train loss: 0.340 Train accuracy: 0.9111\n",
      "Epoch: 12/80 Iteration: 15 Train loss: 0.003 Train accuracy: 0.9115\n",
      "Epoch: 12/80 Iteration: 20 Train loss: 0.405 Train accuracy: 0.9117\n",
      "Epoch: 12/80 Iteration: 25 Train loss: 0.055 Train accuracy: 0.9123\n",
      "Epoch: 12/80 Iteration: 30 Train loss: 0.051 Train accuracy: 0.9131\n",
      "Epoch: 12/80 Iteration: 35 Train loss: 0.008 Train accuracy: 0.9135\n",
      "Train accuracy (mean): 0.9120\n",
      "Epoch: 13/80 Iteration: 5 Train loss: 0.126 Train accuracy: 0.9141\n",
      "Epoch: 13/80 Iteration: 10 Train loss: 0.080 Train accuracy: 0.9144\n",
      "Epoch: 13/80 Iteration: 15 Train loss: 0.047 Train accuracy: 0.9148\n",
      "Epoch: 13/80 Iteration: 20 Train loss: 0.512 Train accuracy: 0.9148\n",
      "Epoch: 13/80 Iteration: 25 Train loss: 0.028 Train accuracy: 0.9155\n",
      "Epoch: 13/80 Iteration: 30 Train loss: 0.002 Train accuracy: 0.9160\n",
      "Epoch: 13/80 Iteration: 35 Train loss: 0.005 Train accuracy: 0.9168\n",
      "Train accuracy (mean): 0.9152\n",
      "Epoch: 14/80 Iteration: 5 Train loss: 0.008 Train accuracy: 0.9180\n",
      "Epoch: 14/80 Iteration: 10 Train loss: 0.036 Train accuracy: 0.9186\n",
      "Epoch: 14/80 Iteration: 15 Train loss: 0.013 Train accuracy: 0.9194\n",
      "Epoch: 14/80 Iteration: 20 Train loss: 0.374 Train accuracy: 0.9197\n",
      "Epoch: 14/80 Iteration: 25 Train loss: 0.026 Train accuracy: 0.9204\n",
      "Epoch: 14/80 Iteration: 30 Train loss: 0.010 Train accuracy: 0.9210\n",
      "Epoch: 14/80 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9217\n",
      "Train accuracy (mean): 0.9197\n",
      "Epoch: 15/80 Iteration: 5 Train loss: 0.004 Train accuracy: 0.9226\n",
      "Epoch: 15/80 Iteration: 10 Train loss: 0.018 Train accuracy: 0.9231\n",
      "Epoch: 15/80 Iteration: 15 Train loss: 0.030 Train accuracy: 0.9237\n",
      "Epoch: 15/80 Iteration: 20 Train loss: 0.161 Train accuracy: 0.9240\n",
      "Epoch: 15/80 Iteration: 25 Train loss: 0.120 Train accuracy: 0.9244\n",
      "Epoch: 15/80 Iteration: 30 Train loss: 0.006 Train accuracy: 0.9248\n",
      "Epoch: 15/80 Iteration: 35 Train loss: 0.005 Train accuracy: 0.9253\n",
      "Train accuracy (mean): 0.9239\n",
      "Epoch: 16/80 Iteration: 5 Train loss: 0.030 Train accuracy: 0.9258\n",
      "Epoch: 16/80 Iteration: 10 Train loss: 0.121 Train accuracy: 0.9260\n",
      "Epoch: 16/80 Iteration: 15 Train loss: 0.008 Train accuracy: 0.9266\n",
      "Epoch: 16/80 Iteration: 20 Train loss: 0.064 Train accuracy: 0.9270\n",
      "Epoch: 16/80 Iteration: 25 Train loss: 0.040 Train accuracy: 0.9277\n",
      "Epoch: 16/80 Iteration: 30 Train loss: 0.022 Train accuracy: 0.9280\n",
      "Epoch: 16/80 Iteration: 35 Train loss: 0.009 Train accuracy: 0.9285\n",
      "Train accuracy (mean): 0.9270\n",
      "Epoch: 17/80 Iteration: 5 Train loss: 0.004 Train accuracy: 0.9291\n",
      "Epoch: 17/80 Iteration: 10 Train loss: 0.023 Train accuracy: 0.9295\n",
      "Epoch: 17/80 Iteration: 15 Train loss: 0.004 Train accuracy: 0.9300\n",
      "Epoch: 17/80 Iteration: 20 Train loss: 0.098 Train accuracy: 0.9302\n",
      "Epoch: 17/80 Iteration: 25 Train loss: 0.056 Train accuracy: 0.9306\n",
      "Epoch: 17/80 Iteration: 30 Train loss: 0.018 Train accuracy: 0.9310\n",
      "Epoch: 17/80 Iteration: 35 Train loss: 0.004 Train accuracy: 0.9314\n",
      "Train accuracy (mean): 0.9302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/80 Iteration: 5 Train loss: 0.005 Train accuracy: 0.9320\n",
      "Epoch: 18/80 Iteration: 10 Train loss: 0.086 Train accuracy: 0.9322\n",
      "Epoch: 18/80 Iteration: 15 Train loss: 0.018 Train accuracy: 0.9328\n",
      "Epoch: 18/80 Iteration: 20 Train loss: 0.025 Train accuracy: 0.9332\n",
      "Epoch: 18/80 Iteration: 25 Train loss: 0.077 Train accuracy: 0.9336\n",
      "Epoch: 18/80 Iteration: 30 Train loss: 0.010 Train accuracy: 0.9338\n",
      "Epoch: 18/80 Iteration: 35 Train loss: 0.002 Train accuracy: 0.9342\n",
      "Train accuracy (mean): 0.9330\n",
      "Epoch: 19/80 Iteration: 5 Train loss: 0.003 Train accuracy: 0.9348\n",
      "Epoch: 19/80 Iteration: 10 Train loss: 0.052 Train accuracy: 0.9350\n",
      "Epoch: 19/80 Iteration: 15 Train loss: 0.011 Train accuracy: 0.9355\n",
      "Epoch: 19/80 Iteration: 20 Train loss: 0.026 Train accuracy: 0.9359\n",
      "Epoch: 19/80 Iteration: 25 Train loss: 0.121 Train accuracy: 0.9362\n",
      "Epoch: 19/80 Iteration: 30 Train loss: 0.031 Train accuracy: 0.9364\n",
      "Epoch: 19/80 Iteration: 35 Train loss: 0.002 Train accuracy: 0.9368\n",
      "Train accuracy (mean): 0.9358\n",
      "Epoch: 20/80 Iteration: 5 Train loss: 0.045 Train accuracy: 0.9372\n",
      "Epoch: 20/80 Iteration: 10 Train loss: 0.171 Train accuracy: 0.9374\n",
      "Epoch: 20/80 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9377\n",
      "Epoch: 20/80 Iteration: 20 Train loss: 0.034 Train accuracy: 0.9381\n",
      "Epoch: 20/80 Iteration: 25 Train loss: 0.035 Train accuracy: 0.9385\n",
      "Epoch: 20/80 Iteration: 30 Train loss: 0.064 Train accuracy: 0.9386\n",
      "Epoch: 20/80 Iteration: 35 Train loss: 0.005 Train accuracy: 0.9390\n",
      "Train accuracy (mean): 0.9380\n",
      "Epoch: 21/80 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9394\n",
      "Epoch: 21/80 Iteration: 10 Train loss: 0.040 Train accuracy: 0.9396\n",
      "Epoch: 21/80 Iteration: 15 Train loss: 0.003 Train accuracy: 0.9399\n",
      "Epoch: 21/80 Iteration: 20 Train loss: 0.030 Train accuracy: 0.9402\n",
      "Epoch: 21/80 Iteration: 25 Train loss: 0.124 Train accuracy: 0.9405\n",
      "Epoch: 21/80 Iteration: 30 Train loss: 0.019 Train accuracy: 0.9406\n",
      "Epoch: 21/80 Iteration: 35 Train loss: 0.003 Train accuracy: 0.9409\n",
      "Train accuracy (mean): 0.9401\n",
      "Epoch: 22/80 Iteration: 5 Train loss: 0.003 Train accuracy: 0.9414\n",
      "Epoch: 22/80 Iteration: 10 Train loss: 0.063 Train accuracy: 0.9415\n",
      "Epoch: 22/80 Iteration: 15 Train loss: 0.010 Train accuracy: 0.9418\n",
      "Epoch: 22/80 Iteration: 20 Train loss: 0.024 Train accuracy: 0.9421\n",
      "Epoch: 22/80 Iteration: 25 Train loss: 0.104 Train accuracy: 0.9424\n",
      "Epoch: 22/80 Iteration: 30 Train loss: 0.003 Train accuracy: 0.9425\n",
      "Epoch: 22/80 Iteration: 35 Train loss: 0.008 Train accuracy: 0.9428\n",
      "Train accuracy (mean): 0.9420\n",
      "Epoch: 23/80 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9432\n",
      "Epoch: 23/80 Iteration: 10 Train loss: 0.009 Train accuracy: 0.9433\n",
      "Epoch: 23/80 Iteration: 15 Train loss: 0.037 Train accuracy: 0.9437\n",
      "Epoch: 23/80 Iteration: 20 Train loss: 0.023 Train accuracy: 0.9439\n",
      "Epoch: 23/80 Iteration: 25 Train loss: 0.128 Train accuracy: 0.9441\n",
      "Epoch: 23/80 Iteration: 30 Train loss: 0.023 Train accuracy: 0.9442\n",
      "Epoch: 23/80 Iteration: 35 Train loss: 0.006 Train accuracy: 0.9445\n",
      "Train accuracy (mean): 0.9438\n",
      "Epoch: 24/80 Iteration: 5 Train loss: 0.005 Train accuracy: 0.9449\n",
      "Epoch: 24/80 Iteration: 10 Train loss: 0.087 Train accuracy: 0.9450\n",
      "Epoch: 24/80 Iteration: 15 Train loss: 0.003 Train accuracy: 0.9453\n",
      "Epoch: 24/80 Iteration: 20 Train loss: 0.030 Train accuracy: 0.9455\n",
      "Epoch: 24/80 Iteration: 25 Train loss: 0.025 Train accuracy: 0.9458\n",
      "Epoch: 24/80 Iteration: 30 Train loss: 0.245 Train accuracy: 0.9459\n",
      "Epoch: 24/80 Iteration: 35 Train loss: 0.008 Train accuracy: 0.9461\n",
      "Train accuracy (mean): 0.9455\n",
      "Epoch: 25/80 Iteration: 5 Train loss: 0.022 Train accuracy: 0.9462\n",
      "Epoch: 25/80 Iteration: 10 Train loss: 0.139 Train accuracy: 0.9462\n",
      "Epoch: 25/80 Iteration: 15 Train loss: 0.003 Train accuracy: 0.9464\n",
      "Epoch: 25/80 Iteration: 20 Train loss: 0.020 Train accuracy: 0.9466\n",
      "Epoch: 25/80 Iteration: 25 Train loss: 0.005 Train accuracy: 0.9469\n",
      "Epoch: 25/80 Iteration: 30 Train loss: 0.226 Train accuracy: 0.9470\n",
      "Epoch: 25/80 Iteration: 35 Train loss: 0.009 Train accuracy: 0.9471\n",
      "Train accuracy (mean): 0.9466\n",
      "Epoch: 26/80 Iteration: 5 Train loss: 0.006 Train accuracy: 0.9474\n",
      "Epoch: 26/80 Iteration: 10 Train loss: 0.074 Train accuracy: 0.9474\n",
      "Epoch: 26/80 Iteration: 15 Train loss: 0.005 Train accuracy: 0.9476\n",
      "Epoch: 26/80 Iteration: 20 Train loss: 0.027 Train accuracy: 0.9478\n",
      "Epoch: 26/80 Iteration: 25 Train loss: 0.010 Train accuracy: 0.9481\n",
      "Epoch: 26/80 Iteration: 30 Train loss: 0.063 Train accuracy: 0.9483\n",
      "Epoch: 26/80 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9485\n",
      "Train accuracy (mean): 0.9479\n",
      "Epoch: 27/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9487\n",
      "Epoch: 27/80 Iteration: 10 Train loss: 0.013 Train accuracy: 0.9488\n",
      "Epoch: 27/80 Iteration: 15 Train loss: 0.063 Train accuracy: 0.9489\n",
      "Epoch: 27/80 Iteration: 20 Train loss: 0.032 Train accuracy: 0.9491\n",
      "Epoch: 27/80 Iteration: 25 Train loss: 0.038 Train accuracy: 0.9494\n",
      "Epoch: 27/80 Iteration: 30 Train loss: 0.036 Train accuracy: 0.9495\n",
      "Epoch: 27/80 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9496\n",
      "Train accuracy (mean): 0.9491\n",
      "Epoch: 28/80 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9499\n",
      "Epoch: 28/80 Iteration: 10 Train loss: 0.012 Train accuracy: 0.9499\n",
      "Epoch: 28/80 Iteration: 15 Train loss: 0.013 Train accuracy: 0.9501\n",
      "Epoch: 28/80 Iteration: 20 Train loss: 0.042 Train accuracy: 0.9503\n",
      "Epoch: 28/80 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9505\n",
      "Epoch: 28/80 Iteration: 30 Train loss: 0.094 Train accuracy: 0.9507\n",
      "Epoch: 28/80 Iteration: 35 Train loss: 0.012 Train accuracy: 0.9508\n",
      "Train accuracy (mean): 0.9503\n",
      "Epoch: 29/80 Iteration: 5 Train loss: 0.032 Train accuracy: 0.9511\n",
      "Epoch: 29/80 Iteration: 10 Train loss: 0.100 Train accuracy: 0.9512\n",
      "Epoch: 29/80 Iteration: 15 Train loss: 0.002 Train accuracy: 0.9515\n",
      "Epoch: 29/80 Iteration: 20 Train loss: 0.061 Train accuracy: 0.9515\n",
      "Epoch: 29/80 Iteration: 25 Train loss: 0.002 Train accuracy: 0.9517\n",
      "Epoch: 29/80 Iteration: 30 Train loss: 0.035 Train accuracy: 0.9520\n",
      "Epoch: 29/80 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9521\n",
      "Train accuracy (mean): 0.9516\n",
      "Epoch: 30/80 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9523\n",
      "Epoch: 30/80 Iteration: 10 Train loss: 0.013 Train accuracy: 0.9523\n",
      "Epoch: 30/80 Iteration: 15 Train loss: 0.020 Train accuracy: 0.9524\n",
      "Epoch: 30/80 Iteration: 20 Train loss: 0.091 Train accuracy: 0.9526\n",
      "Epoch: 30/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9528\n",
      "Epoch: 30/80 Iteration: 30 Train loss: 0.011 Train accuracy: 0.9530\n",
      "Epoch: 30/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9531\n",
      "Train accuracy (mean): 0.9526\n",
      "Epoch: 31/80 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9532\n",
      "Epoch: 31/80 Iteration: 10 Train loss: 0.004 Train accuracy: 0.9532\n",
      "Epoch: 31/80 Iteration: 15 Train loss: 0.063 Train accuracy: 0.9533\n",
      "Epoch: 31/80 Iteration: 20 Train loss: 0.014 Train accuracy: 0.9535\n",
      "Epoch: 31/80 Iteration: 25 Train loss: 0.007 Train accuracy: 0.9537\n",
      "Epoch: 31/80 Iteration: 30 Train loss: 0.007 Train accuracy: 0.9538\n",
      "Epoch: 31/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9540\n",
      "Train accuracy (mean): 0.9535\n",
      "Epoch: 32/80 Iteration: 5 Train loss: 0.004 Train accuracy: 0.9542\n",
      "Epoch: 32/80 Iteration: 10 Train loss: 0.019 Train accuracy: 0.9543\n",
      "Epoch: 32/80 Iteration: 15 Train loss: 0.022 Train accuracy: 0.9545\n",
      "Epoch: 32/80 Iteration: 20 Train loss: 0.050 Train accuracy: 0.9545\n",
      "Epoch: 32/80 Iteration: 25 Train loss: 0.023 Train accuracy: 0.9546\n",
      "Epoch: 32/80 Iteration: 30 Train loss: 0.002 Train accuracy: 0.9546\n",
      "Epoch: 32/80 Iteration: 35 Train loss: 0.004 Train accuracy: 0.9547\n",
      "Train accuracy (mean): 0.9545\n",
      "Epoch: 33/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9550\n",
      "Epoch: 33/80 Iteration: 10 Train loss: 0.023 Train accuracy: 0.9551\n",
      "Epoch: 33/80 Iteration: 15 Train loss: 0.002 Train accuracy: 0.9552\n",
      "Epoch: 33/80 Iteration: 20 Train loss: 0.025 Train accuracy: 0.9553\n",
      "Epoch: 33/80 Iteration: 25 Train loss: 0.045 Train accuracy: 0.9555\n",
      "Epoch: 33/80 Iteration: 30 Train loss: 0.006 Train accuracy: 0.9555\n",
      "Epoch: 33/80 Iteration: 35 Train loss: 0.003 Train accuracy: 0.9557\n",
      "Train accuracy (mean): 0.9553\n",
      "Epoch: 34/80 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9558\n",
      "Epoch: 34/80 Iteration: 10 Train loss: 0.009 Train accuracy: 0.9559\n",
      "Epoch: 34/80 Iteration: 15 Train loss: 0.007 Train accuracy: 0.9560\n",
      "Epoch: 34/80 Iteration: 20 Train loss: 0.006 Train accuracy: 0.9561\n",
      "Epoch: 34/80 Iteration: 25 Train loss: 0.014 Train accuracy: 0.9563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/80 Iteration: 30 Train loss: 0.099 Train accuracy: 0.9564\n",
      "Epoch: 34/80 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9565\n",
      "Train accuracy (mean): 0.9561\n",
      "Epoch: 35/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9567\n",
      "Epoch: 35/80 Iteration: 10 Train loss: 0.044 Train accuracy: 0.9568\n",
      "Epoch: 35/80 Iteration: 15 Train loss: 0.004 Train accuracy: 0.9569\n",
      "Epoch: 35/80 Iteration: 20 Train loss: 0.007 Train accuracy: 0.9569\n",
      "Epoch: 35/80 Iteration: 25 Train loss: 0.022 Train accuracy: 0.9571\n",
      "Epoch: 35/80 Iteration: 30 Train loss: 0.013 Train accuracy: 0.9572\n",
      "Epoch: 35/80 Iteration: 35 Train loss: 0.002 Train accuracy: 0.9573\n",
      "Train accuracy (mean): 0.9570\n",
      "Epoch: 36/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9575\n",
      "Epoch: 36/80 Iteration: 10 Train loss: 0.016 Train accuracy: 0.9576\n",
      "Epoch: 36/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9578\n",
      "Epoch: 36/80 Iteration: 20 Train loss: 0.006 Train accuracy: 0.9579\n",
      "Epoch: 36/80 Iteration: 25 Train loss: 0.002 Train accuracy: 0.9581\n",
      "Epoch: 36/80 Iteration: 30 Train loss: 0.118 Train accuracy: 0.9581\n",
      "Epoch: 36/80 Iteration: 35 Train loss: 0.003 Train accuracy: 0.9582\n",
      "Train accuracy (mean): 0.9579\n",
      "Epoch: 37/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9584\n",
      "Epoch: 37/80 Iteration: 10 Train loss: 0.007 Train accuracy: 0.9585\n",
      "Epoch: 37/80 Iteration: 15 Train loss: 0.002 Train accuracy: 0.9586\n",
      "Epoch: 37/80 Iteration: 20 Train loss: 0.021 Train accuracy: 0.9587\n",
      "Epoch: 37/80 Iteration: 25 Train loss: 0.010 Train accuracy: 0.9588\n",
      "Epoch: 37/80 Iteration: 30 Train loss: 0.002 Train accuracy: 0.9588\n",
      "Epoch: 37/80 Iteration: 35 Train loss: 0.010 Train accuracy: 0.9589\n",
      "Train accuracy (mean): 0.9587\n",
      "Epoch: 38/80 Iteration: 5 Train loss: 0.003 Train accuracy: 0.9591\n",
      "Epoch: 38/80 Iteration: 10 Train loss: 0.037 Train accuracy: 0.9593\n",
      "Epoch: 38/80 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9594\n",
      "Epoch: 38/80 Iteration: 20 Train loss: 0.031 Train accuracy: 0.9595\n",
      "Epoch: 38/80 Iteration: 25 Train loss: 0.005 Train accuracy: 0.9596\n",
      "Epoch: 38/80 Iteration: 30 Train loss: 0.116 Train accuracy: 0.9597\n",
      "Epoch: 38/80 Iteration: 35 Train loss: 0.012 Train accuracy: 0.9598\n",
      "Train accuracy (mean): 0.9595\n",
      "Epoch: 39/80 Iteration: 5 Train loss: 0.146 Train accuracy: 0.9598\n",
      "Epoch: 39/80 Iteration: 10 Train loss: 0.171 Train accuracy: 0.9599\n",
      "Epoch: 39/80 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9600\n",
      "Epoch: 39/80 Iteration: 20 Train loss: 0.058 Train accuracy: 0.9601\n",
      "Epoch: 39/80 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9602\n",
      "Epoch: 39/80 Iteration: 30 Train loss: 0.001 Train accuracy: 0.9603\n",
      "Epoch: 39/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9604\n",
      "Train accuracy (mean): 0.9601\n",
      "Epoch: 40/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9605\n",
      "Epoch: 40/80 Iteration: 10 Train loss: 0.002 Train accuracy: 0.9606\n",
      "Epoch: 40/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9607\n",
      "Epoch: 40/80 Iteration: 20 Train loss: 0.019 Train accuracy: 0.9608\n",
      "Epoch: 40/80 Iteration: 25 Train loss: 0.002 Train accuracy: 0.9610\n",
      "Epoch: 40/80 Iteration: 30 Train loss: 0.168 Train accuracy: 0.9610\n",
      "Epoch: 40/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9611\n",
      "Train accuracy (mean): 0.9608\n",
      "Epoch: 41/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9612\n",
      "Epoch: 41/80 Iteration: 10 Train loss: 0.006 Train accuracy: 0.9613\n",
      "Epoch: 41/80 Iteration: 15 Train loss: 0.025 Train accuracy: 0.9614\n",
      "Epoch: 41/80 Iteration: 20 Train loss: 0.004 Train accuracy: 0.9615\n",
      "Epoch: 41/80 Iteration: 25 Train loss: 0.011 Train accuracy: 0.9616\n",
      "Epoch: 41/80 Iteration: 30 Train loss: 0.049 Train accuracy: 0.9617\n",
      "Epoch: 41/80 Iteration: 35 Train loss: 0.003 Train accuracy: 0.9618\n",
      "Train accuracy (mean): 0.9615\n",
      "Epoch: 42/80 Iteration: 5 Train loss: 0.003 Train accuracy: 0.9619\n",
      "Epoch: 42/80 Iteration: 10 Train loss: 0.009 Train accuracy: 0.9620\n",
      "Epoch: 42/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9621\n",
      "Epoch: 42/80 Iteration: 20 Train loss: 0.005 Train accuracy: 0.9622\n",
      "Epoch: 42/80 Iteration: 25 Train loss: 0.002 Train accuracy: 0.9623\n",
      "Epoch: 42/80 Iteration: 30 Train loss: 0.057 Train accuracy: 0.9624\n",
      "Epoch: 42/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9624\n",
      "Train accuracy (mean): 0.9622\n",
      "Epoch: 43/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9625\n",
      "Epoch: 43/80 Iteration: 10 Train loss: 0.012 Train accuracy: 0.9626\n",
      "Epoch: 43/80 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9627\n",
      "Epoch: 43/80 Iteration: 20 Train loss: 0.003 Train accuracy: 0.9627\n",
      "Epoch: 43/80 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9629\n",
      "Epoch: 43/80 Iteration: 30 Train loss: 0.133 Train accuracy: 0.9629\n",
      "Epoch: 43/80 Iteration: 35 Train loss: 0.006 Train accuracy: 0.9629\n",
      "Train accuracy (mean): 0.9627\n",
      "Epoch: 44/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9630\n",
      "Epoch: 44/80 Iteration: 10 Train loss: 0.010 Train accuracy: 0.9631\n",
      "Epoch: 44/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9632\n",
      "Epoch: 44/80 Iteration: 20 Train loss: 0.007 Train accuracy: 0.9634\n",
      "Epoch: 44/80 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9635\n",
      "Epoch: 44/80 Iteration: 30 Train loss: 0.027 Train accuracy: 0.9635\n",
      "Epoch: 44/80 Iteration: 35 Train loss: 0.002 Train accuracy: 0.9636\n",
      "Train accuracy (mean): 0.9633\n",
      "Epoch: 45/80 Iteration: 5 Train loss: 0.040 Train accuracy: 0.9637\n",
      "Epoch: 45/80 Iteration: 10 Train loss: 0.401 Train accuracy: 0.9638\n",
      "Epoch: 45/80 Iteration: 15 Train loss: 0.137 Train accuracy: 0.9638\n",
      "Epoch: 45/80 Iteration: 20 Train loss: 0.041 Train accuracy: 0.9639\n",
      "Epoch: 45/80 Iteration: 25 Train loss: 0.145 Train accuracy: 0.9638\n",
      "Epoch: 45/80 Iteration: 30 Train loss: 0.001 Train accuracy: 0.9638\n",
      "Epoch: 45/80 Iteration: 35 Train loss: 0.002 Train accuracy: 0.9639\n",
      "Train accuracy (mean): 0.9638\n",
      "Epoch: 46/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9640\n",
      "Epoch: 46/80 Iteration: 10 Train loss: 0.020 Train accuracy: 0.9641\n",
      "Epoch: 46/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9642\n",
      "Epoch: 46/80 Iteration: 20 Train loss: 0.018 Train accuracy: 0.9643\n",
      "Epoch: 46/80 Iteration: 25 Train loss: 0.003 Train accuracy: 0.9644\n",
      "Epoch: 46/80 Iteration: 30 Train loss: 0.040 Train accuracy: 0.9645\n",
      "Epoch: 46/80 Iteration: 35 Train loss: 0.003 Train accuracy: 0.9645\n",
      "Train accuracy (mean): 0.9643\n",
      "Epoch: 47/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9646\n",
      "Epoch: 47/80 Iteration: 10 Train loss: 0.015 Train accuracy: 0.9647\n",
      "Epoch: 47/80 Iteration: 15 Train loss: 0.007 Train accuracy: 0.9648\n",
      "Epoch: 47/80 Iteration: 20 Train loss: 0.016 Train accuracy: 0.9648\n",
      "Epoch: 47/80 Iteration: 25 Train loss: 0.003 Train accuracy: 0.9649\n",
      "Epoch: 47/80 Iteration: 30 Train loss: 0.019 Train accuracy: 0.9650\n",
      "Epoch: 47/80 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9651\n",
      "Train accuracy (mean): 0.9648\n",
      "Epoch: 48/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9651\n",
      "Epoch: 48/80 Iteration: 10 Train loss: 0.001 Train accuracy: 0.9651\n",
      "Epoch: 48/80 Iteration: 15 Train loss: 0.108 Train accuracy: 0.9652\n",
      "Epoch: 48/80 Iteration: 20 Train loss: 0.265 Train accuracy: 0.9652\n",
      "Epoch: 48/80 Iteration: 25 Train loss: 0.064 Train accuracy: 0.9652\n",
      "Epoch: 48/80 Iteration: 30 Train loss: 0.187 Train accuracy: 0.9652\n",
      "Epoch: 48/80 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9653\n",
      "Train accuracy (mean): 0.9652\n",
      "Epoch: 49/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9654\n",
      "Epoch: 49/80 Iteration: 10 Train loss: 0.014 Train accuracy: 0.9654\n",
      "Epoch: 49/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9655\n",
      "Epoch: 49/80 Iteration: 20 Train loss: 0.011 Train accuracy: 0.9655\n",
      "Epoch: 49/80 Iteration: 25 Train loss: 0.005 Train accuracy: 0.9656\n",
      "Epoch: 49/80 Iteration: 30 Train loss: 0.006 Train accuracy: 0.9656\n",
      "Epoch: 49/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9657\n",
      "Train accuracy (mean): 0.9655\n",
      "Epoch: 50/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9657\n",
      "Epoch: 50/80 Iteration: 10 Train loss: 0.063 Train accuracy: 0.9658\n",
      "Epoch: 50/80 Iteration: 15 Train loss: 0.035 Train accuracy: 0.9659\n",
      "Epoch: 50/80 Iteration: 20 Train loss: 0.051 Train accuracy: 0.9659\n",
      "Epoch: 50/80 Iteration: 25 Train loss: 0.007 Train accuracy: 0.9660\n",
      "Epoch: 50/80 Iteration: 30 Train loss: 0.019 Train accuracy: 0.9660\n",
      "Epoch: 50/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9661\n",
      "Train accuracy (mean): 0.9659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/80 Iteration: 5 Train loss: 0.003 Train accuracy: 0.9661\n",
      "Epoch: 51/80 Iteration: 10 Train loss: 0.018 Train accuracy: 0.9661\n",
      "Epoch: 51/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9662\n",
      "Epoch: 51/80 Iteration: 20 Train loss: 0.020 Train accuracy: 0.9663\n",
      "Epoch: 51/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9663\n",
      "Epoch: 51/80 Iteration: 30 Train loss: 0.138 Train accuracy: 0.9663\n",
      "Epoch: 51/80 Iteration: 35 Train loss: 0.005 Train accuracy: 0.9664\n",
      "Train accuracy (mean): 0.9663\n",
      "Epoch: 52/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9665\n",
      "Epoch: 52/80 Iteration: 10 Train loss: 0.006 Train accuracy: 0.9666\n",
      "Epoch: 52/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9667\n",
      "Epoch: 52/80 Iteration: 20 Train loss: 0.009 Train accuracy: 0.9668\n",
      "Epoch: 52/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9668\n",
      "Epoch: 52/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9669\n",
      "Epoch: 52/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9670\n",
      "Train accuracy (mean): 0.9667\n",
      "Epoch: 53/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9671\n",
      "Epoch: 53/80 Iteration: 10 Train loss: 0.001 Train accuracy: 0.9671\n",
      "Epoch: 53/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9672\n",
      "Epoch: 53/80 Iteration: 20 Train loss: 0.001 Train accuracy: 0.9673\n",
      "Epoch: 53/80 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9673\n",
      "Epoch: 53/80 Iteration: 30 Train loss: 0.043 Train accuracy: 0.9674\n",
      "Epoch: 53/80 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9674\n",
      "Train accuracy (mean): 0.9673\n",
      "Epoch: 54/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9675\n",
      "Epoch: 54/80 Iteration: 10 Train loss: 0.003 Train accuracy: 0.9676\n",
      "Epoch: 54/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9676\n",
      "Epoch: 54/80 Iteration: 20 Train loss: 0.004 Train accuracy: 0.9676\n",
      "Epoch: 54/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9677\n",
      "Epoch: 54/80 Iteration: 30 Train loss: 0.089 Train accuracy: 0.9677\n",
      "Epoch: 54/80 Iteration: 35 Train loss: 0.002 Train accuracy: 0.9677\n",
      "Train accuracy (mean): 0.9676\n",
      "Epoch: 55/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9678\n",
      "Epoch: 55/80 Iteration: 10 Train loss: 0.003 Train accuracy: 0.9678\n",
      "Epoch: 55/80 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9678\n",
      "Epoch: 55/80 Iteration: 20 Train loss: 0.048 Train accuracy: 0.9678\n",
      "Epoch: 55/80 Iteration: 25 Train loss: 0.015 Train accuracy: 0.9679\n",
      "Epoch: 55/80 Iteration: 30 Train loss: 0.011 Train accuracy: 0.9680\n",
      "Epoch: 55/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9680\n",
      "Train accuracy (mean): 0.9679\n",
      "Epoch: 56/80 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9681\n",
      "Epoch: 56/80 Iteration: 10 Train loss: 0.011 Train accuracy: 0.9681\n",
      "Epoch: 56/80 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9682\n",
      "Epoch: 56/80 Iteration: 20 Train loss: 0.001 Train accuracy: 0.9682\n",
      "Epoch: 56/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9683\n",
      "Epoch: 56/80 Iteration: 30 Train loss: 0.084 Train accuracy: 0.9683\n",
      "Epoch: 56/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9684\n",
      "Train accuracy (mean): 0.9682\n",
      "Epoch: 57/80 Iteration: 5 Train loss: 0.005 Train accuracy: 0.9684\n",
      "Epoch: 57/80 Iteration: 10 Train loss: 0.004 Train accuracy: 0.9684\n",
      "Epoch: 57/80 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9685\n",
      "Epoch: 57/80 Iteration: 20 Train loss: 0.001 Train accuracy: 0.9686\n",
      "Epoch: 57/80 Iteration: 25 Train loss: 0.004 Train accuracy: 0.9686\n",
      "Epoch: 57/80 Iteration: 30 Train loss: 0.130 Train accuracy: 0.9686\n",
      "Epoch: 57/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9687\n",
      "Train accuracy (mean): 0.9685\n",
      "Epoch: 58/80 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9687\n",
      "Epoch: 58/80 Iteration: 10 Train loss: 0.006 Train accuracy: 0.9688\n",
      "Epoch: 58/80 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9688\n",
      "Epoch: 58/80 Iteration: 20 Train loss: 0.009 Train accuracy: 0.9689\n",
      "Epoch: 58/80 Iteration: 25 Train loss: 0.158 Train accuracy: 0.9689\n",
      "Epoch: 58/80 Iteration: 30 Train loss: 0.030 Train accuracy: 0.9689\n",
      "Epoch: 58/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9689\n",
      "Train accuracy (mean): 0.9688\n",
      "Epoch: 59/80 Iteration: 5 Train loss: 0.007 Train accuracy: 0.9689\n",
      "Epoch: 59/80 Iteration: 10 Train loss: 0.015 Train accuracy: 0.9690\n",
      "Epoch: 59/80 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9690\n",
      "Epoch: 59/80 Iteration: 20 Train loss: 0.013 Train accuracy: 0.9691\n",
      "Epoch: 59/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9692\n",
      "Epoch: 59/80 Iteration: 30 Train loss: 0.105 Train accuracy: 0.9692\n",
      "Epoch: 59/80 Iteration: 35 Train loss: 0.023 Train accuracy: 0.9692\n",
      "Train accuracy (mean): 0.9691\n",
      "Epoch: 60/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9693\n",
      "Epoch: 60/80 Iteration: 10 Train loss: 0.009 Train accuracy: 0.9693\n",
      "Epoch: 60/80 Iteration: 15 Train loss: 0.003 Train accuracy: 0.9694\n",
      "Epoch: 60/80 Iteration: 20 Train loss: 0.003 Train accuracy: 0.9694\n",
      "Epoch: 60/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9695\n",
      "Epoch: 60/80 Iteration: 30 Train loss: 0.011 Train accuracy: 0.9695\n",
      "Epoch: 60/80 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9695\n",
      "Train accuracy (mean): 0.9694\n",
      "Epoch: 61/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9695\n",
      "Epoch: 61/80 Iteration: 10 Train loss: 0.009 Train accuracy: 0.9695\n",
      "Epoch: 61/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9696\n",
      "Epoch: 61/80 Iteration: 20 Train loss: 0.004 Train accuracy: 0.9696\n",
      "Epoch: 61/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9697\n",
      "Epoch: 61/80 Iteration: 30 Train loss: 0.008 Train accuracy: 0.9697\n",
      "Epoch: 61/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9698\n",
      "Train accuracy (mean): 0.9696\n",
      "Epoch: 62/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9698\n",
      "Epoch: 62/80 Iteration: 10 Train loss: 0.012 Train accuracy: 0.9699\n",
      "Epoch: 62/80 Iteration: 15 Train loss: 0.008 Train accuracy: 0.9700\n",
      "Epoch: 62/80 Iteration: 20 Train loss: 0.001 Train accuracy: 0.9700\n",
      "Epoch: 62/80 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9701\n",
      "Epoch: 62/80 Iteration: 30 Train loss: 0.032 Train accuracy: 0.9701\n",
      "Epoch: 62/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9702\n",
      "Train accuracy (mean): 0.9700\n",
      "Epoch: 63/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9702\n",
      "Epoch: 63/80 Iteration: 10 Train loss: 0.023 Train accuracy: 0.9703\n",
      "Epoch: 63/80 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9703\n",
      "Epoch: 63/80 Iteration: 20 Train loss: 0.000 Train accuracy: 0.9704\n",
      "Epoch: 63/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9704\n",
      "Epoch: 63/80 Iteration: 30 Train loss: 0.002 Train accuracy: 0.9704\n",
      "Epoch: 63/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9704\n",
      "Train accuracy (mean): 0.9703\n",
      "Epoch: 64/80 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9705\n",
      "Epoch: 64/80 Iteration: 10 Train loss: 0.005 Train accuracy: 0.9705\n",
      "Epoch: 64/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9705\n",
      "Epoch: 64/80 Iteration: 20 Train loss: 0.006 Train accuracy: 0.9706\n",
      "Epoch: 64/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9706\n",
      "Epoch: 64/80 Iteration: 30 Train loss: 0.076 Train accuracy: 0.9706\n",
      "Epoch: 64/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9707\n",
      "Train accuracy (mean): 0.9706\n",
      "Epoch: 65/80 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9707\n",
      "Epoch: 65/80 Iteration: 10 Train loss: 0.004 Train accuracy: 0.9708\n",
      "Epoch: 65/80 Iteration: 15 Train loss: 0.009 Train accuracy: 0.9709\n",
      "Epoch: 65/80 Iteration: 20 Train loss: 0.023 Train accuracy: 0.9709\n",
      "Epoch: 65/80 Iteration: 25 Train loss: 0.021 Train accuracy: 0.9710\n",
      "Epoch: 65/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9710\n",
      "Epoch: 65/80 Iteration: 35 Train loss: 0.071 Train accuracy: 0.9710\n",
      "Train accuracy (mean): 0.9709\n",
      "Epoch: 66/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9711\n",
      "Epoch: 66/80 Iteration: 10 Train loss: 0.016 Train accuracy: 0.9711\n",
      "Epoch: 66/80 Iteration: 15 Train loss: 0.007 Train accuracy: 0.9712\n",
      "Epoch: 66/80 Iteration: 20 Train loss: 0.001 Train accuracy: 0.9712\n",
      "Epoch: 66/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9712\n",
      "Epoch: 66/80 Iteration: 30 Train loss: 0.003 Train accuracy: 0.9713\n",
      "Epoch: 66/80 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9713\n",
      "Train accuracy (mean): 0.9712\n",
      "Epoch: 67/80 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9714\n",
      "Epoch: 67/80 Iteration: 10 Train loss: 0.045 Train accuracy: 0.9714\n",
      "Epoch: 67/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9713\n",
      "Epoch: 67/80 Iteration: 20 Train loss: 0.068 Train accuracy: 0.9713\n",
      "Epoch: 67/80 Iteration: 25 Train loss: 0.148 Train accuracy: 0.9713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/80 Iteration: 30 Train loss: 0.005 Train accuracy: 0.9714\n",
      "Epoch: 67/80 Iteration: 35 Train loss: 0.020 Train accuracy: 0.9714\n",
      "Train accuracy (mean): 0.9713\n",
      "Epoch: 68/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9714\n",
      "Epoch: 68/80 Iteration: 10 Train loss: 0.007 Train accuracy: 0.9714\n",
      "Epoch: 68/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9714\n",
      "Epoch: 68/80 Iteration: 20 Train loss: 0.002 Train accuracy: 0.9715\n",
      "Epoch: 68/80 Iteration: 25 Train loss: 0.003 Train accuracy: 0.9716\n",
      "Epoch: 68/80 Iteration: 30 Train loss: 0.002 Train accuracy: 0.9716\n",
      "Epoch: 68/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9716\n",
      "Train accuracy (mean): 0.9715\n",
      "Epoch: 69/80 Iteration: 5 Train loss: 0.006 Train accuracy: 0.9717\n",
      "Epoch: 69/80 Iteration: 10 Train loss: 0.005 Train accuracy: 0.9717\n",
      "Epoch: 69/80 Iteration: 15 Train loss: 0.018 Train accuracy: 0.9717\n",
      "Epoch: 69/80 Iteration: 20 Train loss: 0.459 Train accuracy: 0.9717\n",
      "Epoch: 69/80 Iteration: 25 Train loss: 0.029 Train accuracy: 0.9718\n",
      "Epoch: 69/80 Iteration: 30 Train loss: 0.001 Train accuracy: 0.9718\n",
      "Epoch: 69/80 Iteration: 35 Train loss: 0.039 Train accuracy: 0.9718\n",
      "Train accuracy (mean): 0.9717\n",
      "Epoch: 70/80 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9719\n",
      "Epoch: 70/80 Iteration: 10 Train loss: 0.015 Train accuracy: 0.9720\n",
      "Epoch: 70/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9720\n",
      "Epoch: 70/80 Iteration: 20 Train loss: 0.002 Train accuracy: 0.9721\n",
      "Epoch: 70/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9721\n",
      "Epoch: 70/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9722\n",
      "Epoch: 70/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9722\n",
      "Train accuracy (mean): 0.9721\n",
      "Epoch: 71/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9723\n",
      "Epoch: 71/80 Iteration: 10 Train loss: 0.032 Train accuracy: 0.9724\n",
      "Epoch: 71/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9724\n",
      "Epoch: 71/80 Iteration: 20 Train loss: 0.002 Train accuracy: 0.9725\n",
      "Epoch: 71/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9725\n",
      "Epoch: 71/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9726\n",
      "Epoch: 71/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9726\n",
      "Train accuracy (mean): 0.9725\n",
      "Epoch: 72/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9727\n",
      "Epoch: 72/80 Iteration: 10 Train loss: 0.002 Train accuracy: 0.9728\n",
      "Epoch: 72/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9728\n",
      "Epoch: 72/80 Iteration: 20 Train loss: 0.000 Train accuracy: 0.9729\n",
      "Epoch: 72/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9729\n",
      "Epoch: 72/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9730\n",
      "Epoch: 72/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9730\n",
      "Train accuracy (mean): 0.9729\n",
      "Epoch: 73/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9731\n",
      "Epoch: 73/80 Iteration: 10 Train loss: 0.001 Train accuracy: 0.9731\n",
      "Epoch: 73/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9732\n",
      "Epoch: 73/80 Iteration: 20 Train loss: 0.000 Train accuracy: 0.9732\n",
      "Epoch: 73/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9733\n",
      "Epoch: 73/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9733\n",
      "Epoch: 73/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9734\n",
      "Train accuracy (mean): 0.9732\n",
      "Epoch: 74/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9735\n",
      "Epoch: 74/80 Iteration: 10 Train loss: 0.002 Train accuracy: 0.9735\n",
      "Epoch: 74/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9735\n",
      "Epoch: 74/80 Iteration: 20 Train loss: 0.000 Train accuracy: 0.9736\n",
      "Epoch: 74/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9736\n",
      "Epoch: 74/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9737\n",
      "Epoch: 74/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9737\n",
      "Train accuracy (mean): 0.9736\n",
      "Epoch: 75/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9738\n",
      "Epoch: 75/80 Iteration: 10 Train loss: 0.002 Train accuracy: 0.9739\n",
      "Epoch: 75/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9739\n",
      "Epoch: 75/80 Iteration: 20 Train loss: 0.000 Train accuracy: 0.9739\n",
      "Epoch: 75/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9740\n",
      "Epoch: 75/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9740\n",
      "Epoch: 75/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9741\n",
      "Train accuracy (mean): 0.9739\n",
      "Epoch: 76/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9742\n",
      "Epoch: 76/80 Iteration: 10 Train loss: 0.002 Train accuracy: 0.9742\n",
      "Epoch: 76/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9742\n",
      "Epoch: 76/80 Iteration: 20 Train loss: 0.000 Train accuracy: 0.9743\n",
      "Epoch: 76/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9743\n",
      "Epoch: 76/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9744\n",
      "Epoch: 76/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9744\n",
      "Train accuracy (mean): 0.9743\n",
      "Epoch: 77/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9745\n",
      "Epoch: 77/80 Iteration: 10 Train loss: 0.002 Train accuracy: 0.9745\n",
      "Epoch: 77/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9746\n",
      "Epoch: 77/80 Iteration: 20 Train loss: 0.000 Train accuracy: 0.9746\n",
      "Epoch: 77/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9747\n",
      "Epoch: 77/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9747\n",
      "Epoch: 77/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9748\n",
      "Train accuracy (mean): 0.9746\n",
      "Epoch: 78/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9748\n",
      "Epoch: 78/80 Iteration: 10 Train loss: 0.002 Train accuracy: 0.9749\n",
      "Epoch: 78/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9749\n",
      "Epoch: 78/80 Iteration: 20 Train loss: 0.000 Train accuracy: 0.9750\n",
      "Epoch: 78/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9750\n",
      "Epoch: 78/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9750\n",
      "Epoch: 78/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9751\n",
      "Train accuracy (mean): 0.9750\n",
      "Epoch: 79/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9751\n",
      "Epoch: 79/80 Iteration: 10 Train loss: 0.002 Train accuracy: 0.9752\n",
      "Epoch: 79/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9752\n",
      "Epoch: 79/80 Iteration: 20 Train loss: 0.000 Train accuracy: 0.9753\n",
      "Epoch: 79/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9753\n",
      "Epoch: 79/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9754\n",
      "Epoch: 79/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9754\n",
      "Train accuracy (mean): 0.9753\n",
      "Epoch: 80/80 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9755\n",
      "Epoch: 80/80 Iteration: 10 Train loss: 0.002 Train accuracy: 0.9755\n",
      "Epoch: 80/80 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9755\n",
      "Epoch: 80/80 Iteration: 20 Train loss: 0.000 Train accuracy: 0.9756\n",
      "Epoch: 80/80 Iteration: 25 Train loss: 0.000 Train accuracy: 0.9756\n",
      "Epoch: 80/80 Iteration: 30 Train loss: 0.000 Train accuracy: 0.9757\n",
      "Epoch: 80/80 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9757\n",
      "Train accuracy (mean): 0.9756\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "epochs = 80\n",
    "model = HappyModel(learning_rate = learning_rate)\n",
    "extra_graphkeys_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "train_acc_mean = []\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver = tf.train.Saver() \n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #start_time=time.time()\n",
    "    for e in range(epochs):\n",
    "        train_acc = []\n",
    "        train_acc_v2 = []\n",
    "        iteration = 1\n",
    "         \n",
    "        for (x, y) in random_mini_batches(X_train, Y_train, mini_batch_size = mini_batch_size, seed = 0):\n",
    "            feed = {model.inputs_: x,\n",
    "                   model.targets_: y,\n",
    "                   model.training: True}\n",
    "\n",
    "            batch_loss, batch_accuracy, batch_acc, batch_acc_op,_, _= sess.run([model.loss, model.accuracy,\n",
    "                                                      model.acc, model.acc_op,\n",
    "                                                      model.optimizer ,extra_graphkeys_update_ops],\n",
    "                                 feed_dict=feed)\n",
    "            \n",
    "            train_acc.append(batch_accuracy)\n",
    "            train_acc_v2.append(batch_acc_op)\n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(batch_loss),\n",
    "                      \"Train accuracy: {:.4f}\".format(batch_acc_op)\n",
    "                     )\n",
    "                     \n",
    "                \n",
    "            iteration +=1\n",
    "    \n",
    "    #duration=time.time()-start_time\n",
    "    #print(\"duration: {:.1f} sec\".format(duration))\n",
    "        print(\"Train accuracy (mean): {:.4f}\".format(np.mean(train_acc_v2)))\n",
    "        train_acc_mean.append(np.mean(train_acc_v2))\n",
    "    saver.save(sess, \"checkpoints/HappyModel.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,epochs+1), train_acc_mean)\n",
    "plt.ylabel('mean accuracy per epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 22:39:06.679410 30984 deprecation.py:323] From <ipython-input-14-011611f3bf71>:26: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv0/kernel:0' shape=(7, 7, 3, 32) dtype=float32_ref>\n",
      "shape of weight matrix:  (7, 7, 3, 32)\n",
      "number of trainable parameters:  4704\n",
      "------------------------------\n",
      "<tf.Variable 'conv0/bias:0' shape=(32,) dtype=float32_ref>\n",
      "shape of weight matrix:  (32,)\n",
      "number of trainable parameters:  32\n",
      "------------------------------\n",
      "<tf.Variable 'bn0/gamma:0' shape=(32,) dtype=float32_ref>\n",
      "shape of weight matrix:  (32,)\n",
      "number of trainable parameters:  32\n",
      "------------------------------\n",
      "<tf.Variable 'bn0/beta:0' shape=(32,) dtype=float32_ref>\n",
      "shape of weight matrix:  (32,)\n",
      "number of trainable parameters:  32\n",
      "------------------------------\n",
      "<tf.Variable 'fully_connected/weights:0' shape=(32768, 1) dtype=float32_ref>\n",
      "shape of weight matrix:  (32768, 1)\n",
      "number of trainable parameters:  32768\n",
      "------------------------------\n",
      "<tf.Variable 'fully_connected/biases:0' shape=(1,) dtype=float32_ref>\n",
      "shape of weight matrix:  (1,)\n",
      "number of trainable parameters:  1\n",
      "------------------------------\n",
      "total number of trainable parameters:  37569\n",
      "total number of parameters:  112773\n"
     ]
    }
   ],
   "source": [
    "# this part calculates the number of trainable parameters\n",
    "\n",
    "model = HappyModel(learning_rate = learning_rate)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        print(variable)\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        print('shape of weight matrix: ',shape)\n",
    "        #print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            #print(dim)\n",
    "            variable_parameters *= dim.value\n",
    "        print('number of trainable parameters: ',variable_parameters)\n",
    "        print('------------------------------')\n",
    "        total_parameters += variable_parameters\n",
    "    print('total number of trainable parameters: ',total_parameters)\n",
    "\n",
    "# this part calculates the number of all the  parameters\n",
    "    total_parameters = 0\n",
    "    for variable in tf.all_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        total_parameters += variable_parameters\n",
    "    print('total number of parameters: ',total_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 22:39:08.365504 30984 deprecation.py:323] From C:\\Users\\vgkortsas\\AppData\\Local\\Continuum\\anaconda3\\envs\\TF_practice\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Test loss: 0.063 Test accuracy: 0.9375\n",
      "Iteration: 2 Test loss: 0.001 Test accuracy: 0.9688\n",
      "Iteration: 3 Test loss: 0.002 Test accuracy: 0.9792\n",
      "Iteration: 4 Test loss: 0.000 Test accuracy: 0.9844\n",
      "Iteration: 5 Test loss: 0.001 Test accuracy: 0.9875\n",
      "Iteration: 6 Test loss: 0.362 Test accuracy: 0.9792\n",
      "Iteration: 7 Test loss: 0.006 Test accuracy: 0.9821\n",
      "Iteration: 8 Test loss: 0.562 Test accuracy: 0.9688\n",
      "Iteration: 9 Test loss: 0.066 Test accuracy: 0.9653\n",
      "Iteration: 10 Test loss: 0.000 Test accuracy: 0.9667\n",
      "Test accuracy (mean): 0.9719 \n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = HappyModel(learning_rate = learning_rate)\n",
    "\n",
    "test_acc = []\n",
    "test_acc_v2 = []\n",
    "\n",
    "with tf.Session(config=config) as sess: \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    iteration = 1\n",
    "    #for (x, y) in get_batches(X_test, Y_test, batch_size):\n",
    "    for (x, y) in random_mini_batches(X_test, Y_test, mini_batch_size = mini_batch_size, seed = 0):\n",
    "        feed = {model.inputs_: x,\n",
    "                   model.targets_: y,\n",
    "                   model.training: False}\n",
    "\n",
    "\n",
    "        batch_loss, batch_accuracy, batch_acc, batch_acc_op = sess.run([model.loss, model.accuracy,\n",
    "                                                                       model.acc, model.acc_op],\n",
    "                                 feed_dict=feed)\n",
    "            \n",
    "        test_acc.append(batch_accuracy)\n",
    "        test_acc_v2.append(batch_acc_op)\n",
    "        \n",
    "        if iteration%1==0:\n",
    "            print(\"Iteration: {}\".format(iteration),\n",
    "                      \"Test loss: {:.3f}\".format(batch_loss),\n",
    "                      \"Test accuracy: {:.4f}\".format(batch_acc_op)\n",
    "                     )\n",
    "                     \n",
    "                \n",
    "        iteration +=1\n",
    "\n",
    "    print(\"Test accuracy (mean): {:.4f} \".format(np.mean(test_acc_v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
