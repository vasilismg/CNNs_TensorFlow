{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Detect hapiness </font>\n",
    "\n",
    "This notebook is based on the programming assignment of deeplearning.ai, course Convolutional Neural Networks, week Deep convolutional models case studies\n",
    "\n",
    "We will build an algorithm that recognizes whether the person in a picture is happy or not.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Application of Convolutional Neural Networks in TensorFlow\n",
    "- Apply Batch Normalization\n",
    "- Use of Adam optimizer \n",
    "- Use of GPU for the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import pydot\n",
    "from IPython.display import SVG\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import time\n",
    "import math\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_happy.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_happy.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "    \n",
    "    inputs_ = tf.placeholder(tf.float32,[None,64,64,3],name='inputs_')\n",
    "    targets_ = tf.placeholder(tf.float32,[None,1], name='targets_')\n",
    "    training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "    \n",
    "    return inputs_, targets_, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss(logits, targets):\n",
    "        \n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=targets))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate):\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HappyModel:\n",
    "    \n",
    "    def __init__(self, learning_rate):\n",
    "    \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs_, self.targets_, self.training = build_inputs()\n",
    "        \n",
    "        # Zero-Padding\n",
    "        paddings = tf.constant([[0, 0], [3, 3,], [3, 3], [0, 0]])\n",
    "        self.X = tf.pad(self.inputs_, paddings, \"CONSTANT\")\n",
    "        \n",
    "        # CONV -> BN -> RELU Block applied to X\n",
    "        strides = 1        \n",
    "        self.X = tf.layers.conv2d(self.X, 32, kernel_size = [7, 7], strides = [strides, strides],\n",
    "                             padding='VALID',name = 'conv0')\n",
    "        self.X = tf.layers.batch_normalization(self.X, training=self.training, name = 'bn0')\n",
    "        self.X = tf.nn.relu(self.X)\n",
    "        \n",
    "        # MAXPOOL\n",
    "        self.X = tf.nn.max_pool(self.X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "        \n",
    "        # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "        self.X = tf.contrib.layers.flatten(self.X)\n",
    "        self.X = tf.contrib.layers.fully_connected(self.X, 1, activation_fn=None)\n",
    "        self.prediction = tf.nn.sigmoid(self.X) \n",
    "        \n",
    "        self.loss = build_loss(self.X, self.targets_)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate)\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.round(self.prediction), self.targets_)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        self.acc, self.acc_op = tf.metrics.accuracy(labels=self.targets_, \n",
    "                                  predictions=tf.round(self.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "mini_batch_size = 16\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "\n",
    "Y_train = tf.transpose(Y_train_orig)\n",
    "Y_test = tf.transpose(Y_test_orig)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#with tf.Session(config=config) as sess:\n",
    "    Y_train,Y_test = sess.run([Y_train,Y_test])\n",
    "    \n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0812 02:40:12.860760 14700 deprecation.py:323] From <ipython-input-9-5c64e489e3d6>:17: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0812 02:40:12.863754 14700 deprecation.py:506] From C:\\Users\\vgkortsas\\AppData\\Local\\Continuum\\anaconda3\\envs\\TF_practice\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0812 02:40:13.023322 14700 deprecation.py:323] From <ipython-input-9-5c64e489e3d6>:18: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0812 02:40:14.190278 14700 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0812 02:40:14.191275 14700 deprecation.py:323] From C:\\Users\\vgkortsas\\AppData\\Local\\Continuum\\anaconda3\\envs\\TF_practice\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0812 02:40:14.588238 14700 deprecation.py:323] From C:\\Users\\vgkortsas\\AppData\\Local\\Continuum\\anaconda3\\envs\\TF_practice\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40 Iteration: 5 Train loss: 5.465 Train accuracy: 0.5375\n",
      "Epoch: 1/40 Iteration: 10 Train loss: 1.772 Train accuracy: 0.5437\n",
      "Epoch: 1/40 Iteration: 15 Train loss: 0.680 Train accuracy: 0.5875\n",
      "Epoch: 1/40 Iteration: 20 Train loss: 0.955 Train accuracy: 0.6125\n",
      "Epoch: 1/40 Iteration: 25 Train loss: 0.266 Train accuracy: 0.6500\n",
      "Epoch: 1/40 Iteration: 30 Train loss: 0.048 Train accuracy: 0.6875\n",
      "Epoch: 1/40 Iteration: 35 Train loss: 0.123 Train accuracy: 0.7125\n",
      "Train accuracy (mean): 0.6173\n",
      "Epoch: 2/40 Iteration: 5 Train loss: 0.599 Train accuracy: 0.7368\n",
      "Epoch: 2/40 Iteration: 10 Train loss: 0.293 Train accuracy: 0.7500\n",
      "Epoch: 2/40 Iteration: 15 Train loss: 0.272 Train accuracy: 0.7655\n",
      "Epoch: 2/40 Iteration: 20 Train loss: 0.253 Train accuracy: 0.7750\n",
      "Epoch: 2/40 Iteration: 25 Train loss: 0.072 Train accuracy: 0.7820\n",
      "Epoch: 2/40 Iteration: 30 Train loss: 0.013 Train accuracy: 0.7898\n",
      "Epoch: 2/40 Iteration: 35 Train loss: 0.087 Train accuracy: 0.7983\n",
      "Train accuracy (mean): 0.7697\n",
      "Epoch: 3/40 Iteration: 5 Train loss: 0.230 Train accuracy: 0.8062\n",
      "Epoch: 3/40 Iteration: 10 Train loss: 0.092 Train accuracy: 0.8110\n",
      "Epoch: 3/40 Iteration: 15 Train loss: 0.055 Train accuracy: 0.8194\n",
      "Epoch: 3/40 Iteration: 20 Train loss: 0.202 Train accuracy: 0.8263\n",
      "Epoch: 3/40 Iteration: 25 Train loss: 0.040 Train accuracy: 0.8344\n",
      "Epoch: 3/40 Iteration: 30 Train loss: 0.090 Train accuracy: 0.8411\n",
      "Epoch: 3/40 Iteration: 35 Train loss: 0.200 Train accuracy: 0.8455\n",
      "Train accuracy (mean): 0.8257\n",
      "Epoch: 4/40 Iteration: 5 Train loss: 0.142 Train accuracy: 0.8473\n",
      "Epoch: 4/40 Iteration: 10 Train loss: 0.160 Train accuracy: 0.8474\n",
      "Epoch: 4/40 Iteration: 15 Train loss: 0.035 Train accuracy: 0.8505\n",
      "Epoch: 4/40 Iteration: 20 Train loss: 0.230 Train accuracy: 0.8538\n",
      "Epoch: 4/40 Iteration: 25 Train loss: 0.051 Train accuracy: 0.8586\n",
      "Epoch: 4/40 Iteration: 30 Train loss: 0.091 Train accuracy: 0.8627\n",
      "Epoch: 4/40 Iteration: 35 Train loss: 0.185 Train accuracy: 0.8648\n",
      "Train accuracy (mean): 0.8547\n",
      "Epoch: 5/40 Iteration: 5 Train loss: 0.085 Train accuracy: 0.8653\n",
      "Epoch: 5/40 Iteration: 10 Train loss: 0.054 Train accuracy: 0.8652\n",
      "Epoch: 5/40 Iteration: 15 Train loss: 0.078 Train accuracy: 0.8670\n",
      "Epoch: 5/40 Iteration: 20 Train loss: 0.218 Train accuracy: 0.8684\n",
      "Epoch: 5/40 Iteration: 25 Train loss: 0.041 Train accuracy: 0.8714\n",
      "Epoch: 5/40 Iteration: 30 Train loss: 0.010 Train accuracy: 0.8747\n",
      "Epoch: 5/40 Iteration: 35 Train loss: 0.045 Train accuracy: 0.8770\n",
      "Train accuracy (mean): 0.8697\n",
      "Epoch: 6/40 Iteration: 5 Train loss: 0.038 Train accuracy: 0.8786\n",
      "Epoch: 6/40 Iteration: 10 Train loss: 0.016 Train accuracy: 0.8791\n",
      "Epoch: 6/40 Iteration: 15 Train loss: 0.554 Train accuracy: 0.8802\n",
      "Epoch: 6/40 Iteration: 20 Train loss: 0.320 Train accuracy: 0.8825\n",
      "Epoch: 6/40 Iteration: 25 Train loss: 0.171 Train accuracy: 0.8841\n",
      "Epoch: 6/40 Iteration: 30 Train loss: 0.011 Train accuracy: 0.8856\n",
      "Epoch: 6/40 Iteration: 35 Train loss: 0.031 Train accuracy: 0.8876\n",
      "Train accuracy (mean): 0.8825\n",
      "Epoch: 7/40 Iteration: 5 Train loss: 0.024 Train accuracy: 0.8883\n",
      "Epoch: 7/40 Iteration: 10 Train loss: 0.013 Train accuracy: 0.8891\n",
      "Epoch: 7/40 Iteration: 15 Train loss: 0.315 Train accuracy: 0.8906\n",
      "Epoch: 7/40 Iteration: 20 Train loss: 0.181 Train accuracy: 0.8923\n",
      "Epoch: 7/40 Iteration: 25 Train loss: 0.102 Train accuracy: 0.8940\n",
      "Epoch: 7/40 Iteration: 30 Train loss: 0.015 Train accuracy: 0.8953\n",
      "Epoch: 7/40 Iteration: 35 Train loss: 0.056 Train accuracy: 0.8971\n",
      "Train accuracy (mean): 0.8923\n",
      "Epoch: 8/40 Iteration: 5 Train loss: 0.061 Train accuracy: 0.8972\n",
      "Epoch: 8/40 Iteration: 10 Train loss: 0.011 Train accuracy: 0.8977\n",
      "Epoch: 8/40 Iteration: 15 Train loss: 0.126 Train accuracy: 0.8993\n",
      "Epoch: 8/40 Iteration: 20 Train loss: 0.196 Train accuracy: 0.9007\n",
      "Epoch: 8/40 Iteration: 25 Train loss: 0.038 Train accuracy: 0.9020\n",
      "Epoch: 8/40 Iteration: 30 Train loss: 0.057 Train accuracy: 0.9028\n",
      "Epoch: 8/40 Iteration: 35 Train loss: 0.185 Train accuracy: 0.9034\n",
      "Train accuracy (mean): 0.9004\n",
      "Epoch: 9/40 Iteration: 5 Train loss: 0.026 Train accuracy: 0.9039\n",
      "Epoch: 9/40 Iteration: 10 Train loss: 0.021 Train accuracy: 0.9040\n",
      "Epoch: 9/40 Iteration: 15 Train loss: 0.280 Train accuracy: 0.9050\n",
      "Epoch: 9/40 Iteration: 20 Train loss: 0.245 Train accuracy: 0.9057\n",
      "Epoch: 9/40 Iteration: 25 Train loss: 0.039 Train accuracy: 0.9071\n",
      "Epoch: 9/40 Iteration: 30 Train loss: 0.017 Train accuracy: 0.9080\n",
      "Epoch: 9/40 Iteration: 35 Train loss: 0.024 Train accuracy: 0.9090\n",
      "Train accuracy (mean): 0.9060\n",
      "Epoch: 10/40 Iteration: 5 Train loss: 0.295 Train accuracy: 0.9091\n",
      "Epoch: 10/40 Iteration: 10 Train loss: 0.275 Train accuracy: 0.9095\n",
      "Epoch: 10/40 Iteration: 15 Train loss: 0.493 Train accuracy: 0.9099\n",
      "Epoch: 10/40 Iteration: 20 Train loss: 0.149 Train accuracy: 0.9107\n",
      "Epoch: 10/40 Iteration: 25 Train loss: 0.009 Train accuracy: 0.9112\n",
      "Epoch: 10/40 Iteration: 30 Train loss: 0.241 Train accuracy: 0.9117\n",
      "Epoch: 10/40 Iteration: 35 Train loss: 0.247 Train accuracy: 0.9121\n",
      "Train accuracy (mean): 0.9106\n",
      "Epoch: 11/40 Iteration: 5 Train loss: 0.021 Train accuracy: 0.9117\n",
      "Epoch: 11/40 Iteration: 10 Train loss: 0.148 Train accuracy: 0.9120\n",
      "Epoch: 11/40 Iteration: 15 Train loss: 0.089 Train accuracy: 0.9130\n",
      "Epoch: 11/40 Iteration: 20 Train loss: 0.271 Train accuracy: 0.9133\n",
      "Epoch: 11/40 Iteration: 25 Train loss: 0.004 Train accuracy: 0.9134\n",
      "Epoch: 11/40 Iteration: 30 Train loss: 0.369 Train accuracy: 0.9134\n",
      "Epoch: 11/40 Iteration: 35 Train loss: 0.151 Train accuracy: 0.9140\n",
      "Train accuracy (mean): 0.9129\n",
      "Epoch: 12/40 Iteration: 5 Train loss: 0.273 Train accuracy: 0.9130\n",
      "Epoch: 12/40 Iteration: 10 Train loss: 0.258 Train accuracy: 0.9136\n",
      "Epoch: 12/40 Iteration: 15 Train loss: 0.003 Train accuracy: 0.9140\n",
      "Epoch: 12/40 Iteration: 20 Train loss: 0.544 Train accuracy: 0.9140\n",
      "Epoch: 12/40 Iteration: 25 Train loss: 0.096 Train accuracy: 0.9139\n",
      "Epoch: 12/40 Iteration: 30 Train loss: 0.065 Train accuracy: 0.9147\n",
      "Epoch: 12/40 Iteration: 35 Train loss: 0.019 Train accuracy: 0.9149\n",
      "Train accuracy (mean): 0.9140\n",
      "Epoch: 13/40 Iteration: 5 Train loss: 0.472 Train accuracy: 0.9148\n",
      "Epoch: 13/40 Iteration: 10 Train loss: 0.251 Train accuracy: 0.9152\n",
      "Epoch: 13/40 Iteration: 15 Train loss: 0.008 Train accuracy: 0.9159\n",
      "Epoch: 13/40 Iteration: 20 Train loss: 0.364 Train accuracy: 0.9165\n",
      "Epoch: 13/40 Iteration: 25 Train loss: 0.028 Train accuracy: 0.9174\n",
      "Epoch: 13/40 Iteration: 30 Train loss: 0.010 Train accuracy: 0.9181\n",
      "Epoch: 13/40 Iteration: 35 Train loss: 0.006 Train accuracy: 0.9188\n",
      "Train accuracy (mean): 0.9167\n",
      "Epoch: 14/40 Iteration: 5 Train loss: 0.011 Train accuracy: 0.9198\n",
      "Epoch: 14/40 Iteration: 10 Train loss: 0.056 Train accuracy: 0.9202\n",
      "Epoch: 14/40 Iteration: 15 Train loss: 0.014 Train accuracy: 0.9206\n",
      "Epoch: 14/40 Iteration: 20 Train loss: 0.391 Train accuracy: 0.9209\n",
      "Epoch: 14/40 Iteration: 25 Train loss: 0.048 Train accuracy: 0.9215\n",
      "Epoch: 14/40 Iteration: 30 Train loss: 0.044 Train accuracy: 0.9221\n",
      "Epoch: 14/40 Iteration: 35 Train loss: 0.007 Train accuracy: 0.9224\n",
      "Train accuracy (mean): 0.9210\n",
      "Epoch: 15/40 Iteration: 5 Train loss: 0.064 Train accuracy: 0.9230\n",
      "Epoch: 15/40 Iteration: 10 Train loss: 0.045 Train accuracy: 0.9231\n",
      "Epoch: 15/40 Iteration: 15 Train loss: 0.043 Train accuracy: 0.9234\n",
      "Epoch: 15/40 Iteration: 20 Train loss: 0.436 Train accuracy: 0.9236\n",
      "Epoch: 15/40 Iteration: 25 Train loss: 0.030 Train accuracy: 0.9241\n",
      "Epoch: 15/40 Iteration: 30 Train loss: 0.005 Train accuracy: 0.9247\n",
      "Epoch: 15/40 Iteration: 35 Train loss: 0.002 Train accuracy: 0.9252\n",
      "Train accuracy (mean): 0.9238\n",
      "Epoch: 16/40 Iteration: 5 Train loss: 0.007 Train accuracy: 0.9261\n",
      "Epoch: 16/40 Iteration: 10 Train loss: 0.047 Train accuracy: 0.9264\n",
      "Epoch: 16/40 Iteration: 15 Train loss: 0.012 Train accuracy: 0.9271\n",
      "Epoch: 16/40 Iteration: 20 Train loss: 0.192 Train accuracy: 0.9276\n",
      "Epoch: 16/40 Iteration: 25 Train loss: 0.003 Train accuracy: 0.9281\n",
      "Epoch: 16/40 Iteration: 30 Train loss: 0.011 Train accuracy: 0.9286\n",
      "Epoch: 16/40 Iteration: 35 Train loss: 0.003 Train accuracy: 0.9291\n",
      "Train accuracy (mean): 0.9275\n",
      "Epoch: 17/40 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9299\n",
      "Epoch: 17/40 Iteration: 10 Train loss: 0.036 Train accuracy: 0.9302\n",
      "Epoch: 17/40 Iteration: 15 Train loss: 0.030 Train accuracy: 0.9308\n",
      "Epoch: 17/40 Iteration: 20 Train loss: 0.082 Train accuracy: 0.9310\n",
      "Epoch: 17/40 Iteration: 25 Train loss: 0.035 Train accuracy: 0.9316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/40 Iteration: 30 Train loss: 0.009 Train accuracy: 0.9318\n",
      "Epoch: 17/40 Iteration: 35 Train loss: 0.006 Train accuracy: 0.9323\n",
      "Train accuracy (mean): 0.9310\n",
      "Epoch: 18/40 Iteration: 5 Train loss: 0.010 Train accuracy: 0.9329\n",
      "Epoch: 18/40 Iteration: 10 Train loss: 0.092 Train accuracy: 0.9331\n",
      "Epoch: 18/40 Iteration: 15 Train loss: 0.005 Train accuracy: 0.9336\n",
      "Epoch: 18/40 Iteration: 20 Train loss: 0.041 Train accuracy: 0.9340\n",
      "Epoch: 18/40 Iteration: 25 Train loss: 0.016 Train accuracy: 0.9345\n",
      "Epoch: 18/40 Iteration: 30 Train loss: 0.034 Train accuracy: 0.9348\n",
      "Epoch: 18/40 Iteration: 35 Train loss: 0.004 Train accuracy: 0.9352\n",
      "Train accuracy (mean): 0.9340\n",
      "Epoch: 19/40 Iteration: 5 Train loss: 0.004 Train accuracy: 0.9358\n",
      "Epoch: 19/40 Iteration: 10 Train loss: 0.034 Train accuracy: 0.9361\n",
      "Epoch: 19/40 Iteration: 15 Train loss: 0.009 Train accuracy: 0.9365\n",
      "Epoch: 19/40 Iteration: 20 Train loss: 0.054 Train accuracy: 0.9367\n",
      "Epoch: 19/40 Iteration: 25 Train loss: 0.018 Train accuracy: 0.9371\n",
      "Epoch: 19/40 Iteration: 30 Train loss: 0.017 Train accuracy: 0.9372\n",
      "Epoch: 19/40 Iteration: 35 Train loss: 0.003 Train accuracy: 0.9376\n",
      "Train accuracy (mean): 0.9367\n",
      "Epoch: 20/40 Iteration: 5 Train loss: 0.008 Train accuracy: 0.9382\n",
      "Epoch: 20/40 Iteration: 10 Train loss: 0.078 Train accuracy: 0.9382\n",
      "Epoch: 20/40 Iteration: 15 Train loss: 0.002 Train accuracy: 0.9387\n",
      "Epoch: 20/40 Iteration: 20 Train loss: 0.033 Train accuracy: 0.9390\n",
      "Epoch: 20/40 Iteration: 25 Train loss: 0.042 Train accuracy: 0.9394\n",
      "Epoch: 20/40 Iteration: 30 Train loss: 0.026 Train accuracy: 0.9396\n",
      "Epoch: 20/40 Iteration: 35 Train loss: 0.003 Train accuracy: 0.9400\n",
      "Train accuracy (mean): 0.9390\n",
      "Epoch: 21/40 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9405\n",
      "Epoch: 21/40 Iteration: 10 Train loss: 0.038 Train accuracy: 0.9406\n",
      "Epoch: 21/40 Iteration: 15 Train loss: 0.002 Train accuracy: 0.9409\n",
      "Epoch: 21/40 Iteration: 20 Train loss: 0.034 Train accuracy: 0.9412\n",
      "Epoch: 21/40 Iteration: 25 Train loss: 0.083 Train accuracy: 0.9415\n",
      "Epoch: 21/40 Iteration: 30 Train loss: 0.016 Train accuracy: 0.9416\n",
      "Epoch: 21/40 Iteration: 35 Train loss: 0.005 Train accuracy: 0.9419\n",
      "Train accuracy (mean): 0.9411\n",
      "Epoch: 22/40 Iteration: 5 Train loss: 0.013 Train accuracy: 0.9424\n",
      "Epoch: 22/40 Iteration: 10 Train loss: 0.092 Train accuracy: 0.9425\n",
      "Epoch: 22/40 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9428\n",
      "Epoch: 22/40 Iteration: 20 Train loss: 0.015 Train accuracy: 0.9432\n",
      "Epoch: 22/40 Iteration: 25 Train loss: 0.029 Train accuracy: 0.9435\n",
      "Epoch: 22/40 Iteration: 30 Train loss: 0.093 Train accuracy: 0.9437\n",
      "Epoch: 22/40 Iteration: 35 Train loss: 0.005 Train accuracy: 0.9439\n",
      "Train accuracy (mean): 0.9431\n",
      "Epoch: 23/40 Iteration: 5 Train loss: 0.011 Train accuracy: 0.9442\n",
      "Epoch: 23/40 Iteration: 10 Train loss: 0.042 Train accuracy: 0.9444\n",
      "Epoch: 23/40 Iteration: 15 Train loss: 0.013 Train accuracy: 0.9447\n",
      "Epoch: 23/40 Iteration: 20 Train loss: 0.015 Train accuracy: 0.9450\n",
      "Epoch: 23/40 Iteration: 25 Train loss: 0.076 Train accuracy: 0.9452\n",
      "Epoch: 23/40 Iteration: 30 Train loss: 0.009 Train accuracy: 0.9453\n",
      "Epoch: 23/40 Iteration: 35 Train loss: 0.002 Train accuracy: 0.9456\n",
      "Train accuracy (mean): 0.9449\n",
      "Epoch: 24/40 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9459\n",
      "Epoch: 24/40 Iteration: 10 Train loss: 0.031 Train accuracy: 0.9460\n",
      "Epoch: 24/40 Iteration: 15 Train loss: 0.013 Train accuracy: 0.9462\n",
      "Epoch: 24/40 Iteration: 20 Train loss: 0.013 Train accuracy: 0.9465\n",
      "Epoch: 24/40 Iteration: 25 Train loss: 0.080 Train accuracy: 0.9467\n",
      "Epoch: 24/40 Iteration: 30 Train loss: 0.015 Train accuracy: 0.9468\n",
      "Epoch: 24/40 Iteration: 35 Train loss: 0.002 Train accuracy: 0.9470\n",
      "Train accuracy (mean): 0.9464\n",
      "Epoch: 25/40 Iteration: 5 Train loss: 0.004 Train accuracy: 0.9472\n",
      "Epoch: 25/40 Iteration: 10 Train loss: 0.040 Train accuracy: 0.9473\n",
      "Epoch: 25/40 Iteration: 15 Train loss: 0.005 Train accuracy: 0.9475\n",
      "Epoch: 25/40 Iteration: 20 Train loss: 0.015 Train accuracy: 0.9478\n",
      "Epoch: 25/40 Iteration: 25 Train loss: 0.048 Train accuracy: 0.9480\n",
      "Epoch: 25/40 Iteration: 30 Train loss: 0.047 Train accuracy: 0.9481\n",
      "Epoch: 25/40 Iteration: 35 Train loss: 0.051 Train accuracy: 0.9483\n",
      "Train accuracy (mean): 0.9477\n",
      "Epoch: 26/40 Iteration: 5 Train loss: 0.010 Train accuracy: 0.9486\n",
      "Epoch: 26/40 Iteration: 10 Train loss: 0.181 Train accuracy: 0.9487\n",
      "Epoch: 26/40 Iteration: 15 Train loss: 0.002 Train accuracy: 0.9490\n",
      "Epoch: 26/40 Iteration: 20 Train loss: 0.023 Train accuracy: 0.9491\n",
      "Epoch: 26/40 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9494\n",
      "Epoch: 26/40 Iteration: 30 Train loss: 0.199 Train accuracy: 0.9495\n",
      "Epoch: 26/40 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9496\n",
      "Train accuracy (mean): 0.9491\n",
      "Epoch: 27/40 Iteration: 5 Train loss: 0.006 Train accuracy: 0.9499\n",
      "Epoch: 27/40 Iteration: 10 Train loss: 0.028 Train accuracy: 0.9499\n",
      "Epoch: 27/40 Iteration: 15 Train loss: 0.011 Train accuracy: 0.9501\n",
      "Epoch: 27/40 Iteration: 20 Train loss: 0.015 Train accuracy: 0.9504\n",
      "Epoch: 27/40 Iteration: 25 Train loss: 0.009 Train accuracy: 0.9506\n",
      "Epoch: 27/40 Iteration: 30 Train loss: 0.023 Train accuracy: 0.9507\n",
      "Epoch: 27/40 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9509\n",
      "Train accuracy (mean): 0.9503\n",
      "Epoch: 28/40 Iteration: 5 Train loss: 0.003 Train accuracy: 0.9511\n",
      "Epoch: 28/40 Iteration: 10 Train loss: 0.008 Train accuracy: 0.9512\n",
      "Epoch: 28/40 Iteration: 15 Train loss: 0.052 Train accuracy: 0.9513\n",
      "Epoch: 28/40 Iteration: 20 Train loss: 0.021 Train accuracy: 0.9515\n",
      "Epoch: 28/40 Iteration: 25 Train loss: 0.030 Train accuracy: 0.9517\n",
      "Epoch: 28/40 Iteration: 30 Train loss: 0.065 Train accuracy: 0.9519\n",
      "Epoch: 28/40 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9520\n",
      "Train accuracy (mean): 0.9515\n",
      "Epoch: 29/40 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9523\n",
      "Epoch: 29/40 Iteration: 10 Train loss: 0.013 Train accuracy: 0.9524\n",
      "Epoch: 29/40 Iteration: 15 Train loss: 0.009 Train accuracy: 0.9526\n",
      "Epoch: 29/40 Iteration: 20 Train loss: 0.043 Train accuracy: 0.9527\n",
      "Epoch: 29/40 Iteration: 25 Train loss: 0.015 Train accuracy: 0.9528\n",
      "Epoch: 29/40 Iteration: 30 Train loss: 0.024 Train accuracy: 0.9530\n",
      "Epoch: 29/40 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9531\n",
      "Train accuracy (mean): 0.9527\n",
      "Epoch: 30/40 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9534\n",
      "Epoch: 30/40 Iteration: 10 Train loss: 0.011 Train accuracy: 0.9535\n",
      "Epoch: 30/40 Iteration: 15 Train loss: 0.005 Train accuracy: 0.9537\n",
      "Epoch: 30/40 Iteration: 20 Train loss: 0.067 Train accuracy: 0.9538\n",
      "Epoch: 30/40 Iteration: 25 Train loss: 0.042 Train accuracy: 0.9540\n",
      "Epoch: 30/40 Iteration: 30 Train loss: 0.014 Train accuracy: 0.9540\n",
      "Epoch: 30/40 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9542\n",
      "Train accuracy (mean): 0.9538\n",
      "Epoch: 31/40 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9544\n",
      "Epoch: 31/40 Iteration: 10 Train loss: 0.013 Train accuracy: 0.9545\n",
      "Epoch: 31/40 Iteration: 15 Train loss: 0.002 Train accuracy: 0.9547\n",
      "Epoch: 31/40 Iteration: 20 Train loss: 0.006 Train accuracy: 0.9549\n",
      "Epoch: 31/40 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9551\n",
      "Epoch: 31/40 Iteration: 30 Train loss: 0.233 Train accuracy: 0.9551\n",
      "Epoch: 31/40 Iteration: 35 Train loss: 0.032 Train accuracy: 0.9552\n",
      "Train accuracy (mean): 0.9548\n",
      "Epoch: 32/40 Iteration: 5 Train loss: 0.014 Train accuracy: 0.9554\n",
      "Epoch: 32/40 Iteration: 10 Train loss: 0.219 Train accuracy: 0.9553\n",
      "Epoch: 32/40 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9555\n",
      "Epoch: 32/40 Iteration: 20 Train loss: 0.018 Train accuracy: 0.9557\n",
      "Epoch: 32/40 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9558\n",
      "Epoch: 32/40 Iteration: 30 Train loss: 0.177 Train accuracy: 0.9559\n",
      "Epoch: 32/40 Iteration: 35 Train loss: 0.004 Train accuracy: 0.9559\n",
      "Train accuracy (mean): 0.9556\n",
      "Epoch: 33/40 Iteration: 5 Train loss: 0.016 Train accuracy: 0.9561\n",
      "Epoch: 33/40 Iteration: 10 Train loss: 0.273 Train accuracy: 0.9560\n",
      "Epoch: 33/40 Iteration: 15 Train loss: 0.004 Train accuracy: 0.9562\n",
      "Epoch: 33/40 Iteration: 20 Train loss: 0.024 Train accuracy: 0.9563\n",
      "Epoch: 33/40 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9564\n",
      "Epoch: 33/40 Iteration: 30 Train loss: 0.126 Train accuracy: 0.9565\n",
      "Epoch: 33/40 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9566\n",
      "Train accuracy (mean): 0.9563\n",
      "Epoch: 34/40 Iteration: 5 Train loss: 0.012 Train accuracy: 0.9567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/40 Iteration: 10 Train loss: 0.078 Train accuracy: 0.9568\n",
      "Epoch: 34/40 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9569\n",
      "Epoch: 34/40 Iteration: 20 Train loss: 0.010 Train accuracy: 0.9571\n",
      "Epoch: 34/40 Iteration: 25 Train loss: 0.003 Train accuracy: 0.9572\n",
      "Epoch: 34/40 Iteration: 30 Train loss: 0.141 Train accuracy: 0.9572\n",
      "Epoch: 34/40 Iteration: 35 Train loss: 0.031 Train accuracy: 0.9574\n",
      "Train accuracy (mean): 0.9570\n",
      "Epoch: 35/40 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9576\n",
      "Epoch: 35/40 Iteration: 10 Train loss: 0.092 Train accuracy: 0.9576\n",
      "Epoch: 35/40 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9578\n",
      "Epoch: 35/40 Iteration: 20 Train loss: 0.083 Train accuracy: 0.9579\n",
      "Epoch: 35/40 Iteration: 25 Train loss: 0.003 Train accuracy: 0.9580\n",
      "Epoch: 35/40 Iteration: 30 Train loss: 0.057 Train accuracy: 0.9580\n",
      "Epoch: 35/40 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9581\n",
      "Train accuracy (mean): 0.9578\n",
      "Epoch: 36/40 Iteration: 5 Train loss: 0.006 Train accuracy: 0.9582\n",
      "Epoch: 36/40 Iteration: 10 Train loss: 0.151 Train accuracy: 0.9581\n",
      "Epoch: 36/40 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9583\n",
      "Epoch: 36/40 Iteration: 20 Train loss: 0.022 Train accuracy: 0.9584\n",
      "Epoch: 36/40 Iteration: 25 Train loss: 0.004 Train accuracy: 0.9586\n",
      "Epoch: 36/40 Iteration: 30 Train loss: 0.049 Train accuracy: 0.9587\n",
      "Epoch: 36/40 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9588\n",
      "Train accuracy (mean): 0.9584\n",
      "Epoch: 37/40 Iteration: 5 Train loss: 0.001 Train accuracy: 0.9589\n",
      "Epoch: 37/40 Iteration: 10 Train loss: 0.030 Train accuracy: 0.9588\n",
      "Epoch: 37/40 Iteration: 15 Train loss: 0.053 Train accuracy: 0.9590\n",
      "Epoch: 37/40 Iteration: 20 Train loss: 0.053 Train accuracy: 0.9590\n",
      "Epoch: 37/40 Iteration: 25 Train loss: 0.002 Train accuracy: 0.9592\n",
      "Epoch: 37/40 Iteration: 30 Train loss: 0.027 Train accuracy: 0.9592\n",
      "Epoch: 37/40 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9594\n",
      "Train accuracy (mean): 0.9591\n",
      "Epoch: 38/40 Iteration: 5 Train loss: 0.004 Train accuracy: 0.9595\n",
      "Epoch: 38/40 Iteration: 10 Train loss: 0.017 Train accuracy: 0.9595\n",
      "Epoch: 38/40 Iteration: 15 Train loss: 0.000 Train accuracy: 0.9597\n",
      "Epoch: 38/40 Iteration: 20 Train loss: 0.079 Train accuracy: 0.9598\n",
      "Epoch: 38/40 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9599\n",
      "Epoch: 38/40 Iteration: 30 Train loss: 0.041 Train accuracy: 0.9600\n",
      "Epoch: 38/40 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9601\n",
      "Train accuracy (mean): 0.9598\n",
      "Epoch: 39/40 Iteration: 5 Train loss: 0.002 Train accuracy: 0.9602\n",
      "Epoch: 39/40 Iteration: 10 Train loss: 0.006 Train accuracy: 0.9602\n",
      "Epoch: 39/40 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9603\n",
      "Epoch: 39/40 Iteration: 20 Train loss: 0.003 Train accuracy: 0.9604\n",
      "Epoch: 39/40 Iteration: 25 Train loss: 0.001 Train accuracy: 0.9606\n",
      "Epoch: 39/40 Iteration: 30 Train loss: 0.089 Train accuracy: 0.9606\n",
      "Epoch: 39/40 Iteration: 35 Train loss: 0.000 Train accuracy: 0.9607\n",
      "Train accuracy (mean): 0.9604\n",
      "Epoch: 40/40 Iteration: 5 Train loss: 0.000 Train accuracy: 0.9607\n",
      "Epoch: 40/40 Iteration: 10 Train loss: 0.018 Train accuracy: 0.9607\n",
      "Epoch: 40/40 Iteration: 15 Train loss: 0.001 Train accuracy: 0.9609\n",
      "Epoch: 40/40 Iteration: 20 Train loss: 0.004 Train accuracy: 0.9609\n",
      "Epoch: 40/40 Iteration: 25 Train loss: 0.004 Train accuracy: 0.9611\n",
      "Epoch: 40/40 Iteration: 30 Train loss: 0.031 Train accuracy: 0.9611\n",
      "Epoch: 40/40 Iteration: 35 Train loss: 0.001 Train accuracy: 0.9612\n",
      "Train accuracy (mean): 0.9609\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "epochs = 40\n",
    "model = HappyModel(learning_rate = learning_rate)\n",
    "extra_graphkeys_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "#train_acc = []\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver = tf.train.Saver() \n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #start_time=time.time()\n",
    "    for e in range(epochs):\n",
    "        train_acc = []\n",
    "        train_acc_v2 = []\n",
    "        iteration = 1\n",
    "         \n",
    "        #for (x, y) in get_batches(X_train, Y_train, batch_size):\n",
    "        for (x, y) in random_mini_batches(X_train, Y_train, mini_batch_size = mini_batch_size, seed = 0):\n",
    "            feed = {model.inputs_: x,\n",
    "                   model.targets_: y,\n",
    "                   model.training: True}\n",
    "\n",
    "            batch_loss, batch_accuracy, batch_acc, batch_acc_op,_, _= sess.run([model.loss, model.accuracy,\n",
    "                                                      model.acc, model.acc_op,\n",
    "                                                      model.optimizer ,extra_graphkeys_update_ops],\n",
    "                                 feed_dict=feed)\n",
    "            \n",
    "            train_acc.append(batch_accuracy)\n",
    "            train_acc_v2.append(batch_acc_op)\n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(batch_loss),\n",
    "                      \"Train accuracy: {:.4f}\".format(batch_acc_op)\n",
    "                     )\n",
    "                     \n",
    "                \n",
    "            iteration +=1\n",
    "    \n",
    "    #duration=time.time()-start_time\n",
    "    #print(\"duration: {:.1f} sec\".format(duration))\n",
    "        print(\"Train accuracy (mean): {:.4f}\".format(np.mean(train_acc_v2)))\n",
    "    saver.save(sess, \"checkpoints/HappyModel.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 02:40:30.423267 14700 deprecation.py:323] From <ipython-input-13-721d400b7d4a>:26: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv0/kernel:0' shape=(7, 7, 3, 32) dtype=float32_ref>\n",
      "shape of weight matrix:  (7, 7, 3, 32)\n",
      "number of trainable parameters:  4704\n",
      "------------------------------\n",
      "<tf.Variable 'conv0/bias:0' shape=(32,) dtype=float32_ref>\n",
      "shape of weight matrix:  (32,)\n",
      "number of trainable parameters:  32\n",
      "------------------------------\n",
      "<tf.Variable 'bn0/gamma:0' shape=(32,) dtype=float32_ref>\n",
      "shape of weight matrix:  (32,)\n",
      "number of trainable parameters:  32\n",
      "------------------------------\n",
      "<tf.Variable 'bn0/beta:0' shape=(32,) dtype=float32_ref>\n",
      "shape of weight matrix:  (32,)\n",
      "number of trainable parameters:  32\n",
      "------------------------------\n",
      "<tf.Variable 'fully_connected/weights:0' shape=(32768, 1) dtype=float32_ref>\n",
      "shape of weight matrix:  (32768, 1)\n",
      "number of trainable parameters:  32768\n",
      "------------------------------\n",
      "<tf.Variable 'fully_connected/biases:0' shape=(1,) dtype=float32_ref>\n",
      "shape of weight matrix:  (1,)\n",
      "number of trainable parameters:  1\n",
      "------------------------------\n",
      "total number of trainable parameters:  37569\n",
      "total number of parameters:  112773\n"
     ]
    }
   ],
   "source": [
    "# this part calculates the number of trainable parameters\n",
    "\n",
    "model = HappyModel(learning_rate = learning_rate)\n",
    "#with tf.Session() as sess:\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        print(variable)\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        print('shape of weight matrix: ',shape)\n",
    "        #print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            #print(dim)\n",
    "            variable_parameters *= dim.value\n",
    "        print('number of trainable parameters: ',variable_parameters)\n",
    "        print('------------------------------')\n",
    "        total_parameters += variable_parameters\n",
    "    print('total number of trainable parameters: ',total_parameters)\n",
    "\n",
    "# this part calculates the number of all the  parameters\n",
    "    total_parameters = 0\n",
    "    for variable in tf.all_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        total_parameters += variable_parameters\n",
    "    print('total number of parameters: ',total_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 02:40:44.601212 14700 deprecation.py:323] From C:\\Users\\vgkortsas\\AppData\\Local\\Continuum\\anaconda3\\envs\\TF_practice\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Test loss: 0.379 Test accuracy: 0.8750\n",
      "Iteration: 2 Test loss: 0.113 Test accuracy: 0.9062\n",
      "Iteration: 3 Test loss: 0.022 Test accuracy: 0.9375\n",
      "Iteration: 4 Test loss: 0.084 Test accuracy: 0.9375\n",
      "Iteration: 5 Test loss: 0.426 Test accuracy: 0.9250\n",
      "Iteration: 6 Test loss: 0.089 Test accuracy: 0.9271\n",
      "Iteration: 7 Test loss: 0.564 Test accuracy: 0.9196\n",
      "Iteration: 8 Test loss: 0.671 Test accuracy: 0.9141\n",
      "Iteration: 9 Test loss: 0.561 Test accuracy: 0.9028\n",
      "Iteration: 10 Test loss: 0.002 Test accuracy: 0.9067\n",
      "Test accuracy (mean): 0.9151 \n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = HappyModel(learning_rate = learning_rate)\n",
    "\n",
    "test_acc = []\n",
    "test_acc_v2 = []\n",
    "#with tf.Session() as sess:\n",
    "with tf.Session(config=config) as sess: \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    iteration = 1\n",
    "    #for (x, y) in get_batches(X_test, Y_test, batch_size):\n",
    "    for (x, y) in random_mini_batches(X_test, Y_test, mini_batch_size = mini_batch_size, seed = 0):\n",
    "        feed = {model.inputs_: x,\n",
    "                   model.targets_: y,\n",
    "                   model.training: False}\n",
    "\n",
    "\n",
    "        batch_loss, batch_accuracy, batch_acc, batch_acc_op = sess.run([model.loss, model.accuracy,\n",
    "                                                                       model.acc, model.acc_op],\n",
    "                                 feed_dict=feed)\n",
    "            \n",
    "        test_acc.append(batch_accuracy)\n",
    "        test_acc_v2.append(batch_acc_op)\n",
    "        \n",
    "        if iteration%1==0:\n",
    "            print(\"Iteration: {}\".format(iteration),\n",
    "                      \"Test loss: {:.3f}\".format(batch_loss),\n",
    "                      \"Test accuracy: {:.4f}\".format(batch_acc_op)\n",
    "                     )\n",
    "                     \n",
    "                \n",
    "        iteration +=1\n",
    "\n",
    "    print(\"Test accuracy (mean): {:.4f} \".format(np.mean(test_acc_v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
